{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Splitting a big file by row and by size then combining it back\n",
    "\n",
    "\n",
    "often times, while dealing with big files, \n",
    "we need to split files into smaller chunks and later combine it back.\n",
    "\n",
    "In this notebook, we will use `ChatGPT` coding skills to create a script to perform these tasks.\n",
    "\n",
    "- Test `csv` file, take statistical measurements for comparison\n",
    "- we will first split csv by rows and then by size\n",
    "    - row volume of this file, \n",
    "    - split it, \n",
    "    - combine it back and then reconcile this total stats to verify data quality.\n",
    "- take a huge `video` file, split and combine to see if this code works or not.\n",
    "- take an `image` file, split and combine to see if this code works or not.\n",
    "- take a `zip` including executable file, split and combine to see if this code works or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test csv file\n",
    "\n",
    "run code to capture stats \n",
    "\n",
    "#### rows, total, mean, median\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# create RPA Virtual environment\n",
    "################################\n",
    "# py -m venv RPA\n",
    "# RPA\\Scripts\\activate.bat\n",
    "# import sys\n",
    "# sys.path\n",
    "# py -m pip --version\n",
    "################################\n",
    "## MAKE SURE these packages\n",
    "## are installed\n",
    "################################\n",
    "# pip install pandas\n",
    "\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total    118000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a sample csv file\n",
    "# read file to DataFrame\n",
    "# note stats for reconciliation\n",
    "################################\n",
    "\n",
    "import pandas as pd\n",
    "dfBefore=pd.read_csv(\"../SampleData/sampleData.csv\")\n",
    "dfBefore.head(5)\n",
    "dfBefore[\"Total\"].mean(), \n",
    "dfBefore[[\"Total\"]].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### copy paste ChatGPT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the file\n",
    "# run this code in python\n",
    "# terminal\n",
    "\n",
    "## - Python code\n",
    "\n",
    "## CHANGE CHUNK SIZE, \n",
    "# 1024 = 1kb which is too small\n",
    "## CHANGE FILE NAME BELOW\n",
    "chunk_size = 1024 # define size\n",
    "\n",
    "# name of big file to split\n",
    "filename='../SampleData/sampleData.csv'\n",
    "\n",
    "##\n",
    "## Don't forget \n",
    "## import os statement\n",
    "##\n",
    "import os\n",
    "# read the big file in binary mode\n",
    "with open(filename, 'rb') as infile: # initialize chunk count to 0\n",
    "    chunk_count = 0 \n",
    "    while True:\n",
    "        chunk = infile.read(chunk_size) \n",
    "        # read a chunk of the big file\n",
    "        if not chunk: \n",
    "            # if end of file reached\n",
    "            break\n",
    "        # write the chunk to a new file\n",
    "        # with a numbered suffix\n",
    "        with open(f'{filename}.part{chunk_count}', 'wb') as outfile:\n",
    "            outfile.write(chunk)\n",
    "        chunk_count += 1 # increment chunk count\n",
    "\n",
    "## run readdir() to make sure files are generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read directory to \n",
    "#### verify newly generate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'Amit_TestQRcode.png', 'sampleData.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../SampleData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the split files back \n",
    "# into the original big file\n",
    "\n",
    "with open(filename, 'wb') as outfile:\n",
    "    for i in range(chunk_count):\n",
    "        # read the next split file \n",
    "        # and write its contents to \n",
    "        # the big file\n",
    "        with open(f'{filename}.part{i}', 'rb') as infile:\n",
    "            outfile.write(infile.read())\n",
    "        # delete the split file after it \n",
    "        # has been combined\n",
    "        os.remove(f'{filename}.part{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test combined file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfAfter = pd.read_csv(\"sampleData.csv\")\n",
    "dfAfter.head(5)\n",
    "dfBefore[\"Total\"].mean(), \n",
    "dfAfter[\"Total\"].mean(), \n",
    "dfBefore[[\"compound\", \"Total\"]].median(), \n",
    "dfAfter[[\"compound\", \"Total\"]].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test video file\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "syntax: character literal contains multiple characters",
     "output_type": "error",
     "traceback": [
      "syntax: character literal contains multiple characters",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[2]:9"
     ]
    }
   ],
   "source": [
    "# split the file\n",
    "# run this code in python terminal\n",
    "\n",
    "## - Python code\n",
    "\n",
    "## CHANGE CHUNK SIZE, 1024 = 1kb, which is too small\n",
    "## CHANGE FILE NAME BELOW\n",
    "chunk_size = 1024 # define chunk size in bytes\n",
    "filename = 'bigfile.txt' # name of big file to split\n",
    "\n",
    "# read the big file in binary mode\n",
    "with open(filename, 'rb') as infile:\n",
    "    chunk_count = 0 # initialize chunk count to 0\n",
    "    while True:\n",
    "        chunk = infile.read(chunk_size) # read a chunk of the big file\n",
    "        if not chunk: # if end of file reached\n",
    "            break\n",
    "        # write the chunk to a new file with a numbered suffix\n",
    "        with open(f'{filename}.part{chunk_count}', 'wb') as outfile:\n",
    "            outfile.write(chunk)\n",
    "        chunk_count += 1 # increment chunk count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read directory to verify newly generate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sampleData.csv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"SampleData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### play video file to make sure code works\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the split files back into the original big file\n",
    "\n",
    "with open(filename, 'wb') as outfile:\n",
    "    for i in range(chunk_count):\n",
    "        # read the next split file and write its contents to the big file\n",
    "        with open(f'{filename}.part{i}', 'rb') as infile:\n",
    "            outfile.write(infile.read())\n",
    "        # delete the split file after it has been combined\n",
    "        os.remove(f'{filename}.part{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Zip and Executable files\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the file\n",
    "# run this code in python terminal\n",
    "\n",
    "## - Python code\n",
    "\n",
    "## CHANGE CHUNK SIZE, 1024 = 1kb, which is too small\n",
    "## CHANGE FILE NAME BELOW\n",
    "chunk_size = 1024 # define chunk size in bytes\n",
    "filename = 'bigfile.txt' # name of big file to split\n",
    "\n",
    "# read the big file in binary mode\n",
    "with open(filename, 'rb') as infile:\n",
    "    chunk_count = 0 # initialize chunk count to 0\n",
    "    while True:\n",
    "        chunk = infile.read(chunk_size) # read a chunk of the big file\n",
    "        if not chunk: # if end of file reached\n",
    "            break\n",
    "        # write the chunk to a new file with a numbered suffix\n",
    "        with open(f'{filename}.part{chunk_count}', 'wb') as outfile:\n",
    "            outfile.write(chunk)\n",
    "        chunk_count += 1 # increment chunk count\n",
    "\n",
    "## run readdir() to make sure files are generated\n",
    "\n",
    "# combine the split files back into the original big file\n",
    "\n",
    "\n",
    "with open(filename, 'wb') as outfile:\n",
    "    for i in range(chunk_count):\n",
    "        # read the next split file and write its contents to the big file\n",
    "        with open(f'{filename}.part{i}', 'rb') as infile:\n",
    "            outfile.write(infile.read())\n",
    "        # delete the split file after it has been combined\n",
    "        os.remove(f'{filename}.part{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verify zip and file exe content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "04b8008dc8de53db04c4b46981e564130c4f658f9828d716cf8a3f9d3479d0f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
