{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install manim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install manimgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade \"manim-voiceover[azure,gtts]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"manim-voiceover[transcribe]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manimlib import *\n",
    "\n",
    "# sample example copied from 3b1b\n",
    "\n",
    "class SurfaceExample(Scene):\n",
    "    CONFIG = {\n",
    "        \"camera_class\": ThreeDCamera,\n",
    "    }\n",
    "\n",
    "    def construct(self):\n",
    "        surface_text = Text(\"For 3d scenes, try using surfaces\")\n",
    "        surface_text.fix_in_frame()\n",
    "        surface_text.to_edge(UP)\n",
    "        self.add(surface_text)\n",
    "        self.wait(0.1)\n",
    "\n",
    "        torus1 = Torus(r1=1, r2=1)\n",
    "        torus2 = Torus(r1=3, r2=1)\n",
    "        # sphere = Sphere(radius=3, resolution=torus1.resolution)\n",
    "        sphere = Sphere(radius=3)\n",
    "        # You can texture a surface with up to two images, which will\n",
    "        # be interpreted as the side towards the light, and away from\n",
    "        # the light.  These can be either urls, or paths to a local file\n",
    "        # in whatever you've set as the image directory in\n",
    "        # the custom_config.yml file\n",
    "\n",
    "        # day_texture = \"EarthTextureMap\"\n",
    "        # night_texture = \"NightEarthTextureMap\"\n",
    "        day_texture = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Whole_world_-_land_and_oceans.jpg/1280px-Whole_world_-_land_and_oceans.jpg\"\n",
    "        night_texture = \"https://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/The_earth_at_night.jpg/1280px-The_earth_at_night.jpg\"\n",
    "\n",
    "        surfaces = [\n",
    "            TexturedSurface(surface, day_texture, night_texture)\n",
    "            for surface in [sphere, torus1, torus2]\n",
    "        ]\n",
    "\n",
    "        for mob in surfaces:\n",
    "            mob.shift(IN)\n",
    "            mob.mesh = SurfaceMesh(mob)\n",
    "            mob.mesh.set_stroke(BLUE, 1, opacity=0.5)\n",
    "\n",
    "        # Set perspective\n",
    "        frame = self.camera.frame\n",
    "        frame.set_euler_angles(\n",
    "            theta=-30 * DEGREES,\n",
    "            phi=70 * DEGREES,\n",
    "        )\n",
    "\n",
    "        surface = surfaces[0]\n",
    "\n",
    "        self.play(\n",
    "            FadeIn(surface),\n",
    "            ShowCreation(surface.mesh, lag_ratio=0.01, run_time=3),\n",
    "        )\n",
    "        # for mob in surfaces:\n",
    "        #     mob.add(mob.mesh)\n",
    "        # surface.save_state()\n",
    "        # self.play(Rotate(surface, PI / 2), run_time=2)\n",
    "        # for mob in surfaces[1:]:\n",
    "        #     mob.rotate(PI / 2)\n",
    "\n",
    "        # self.play(\n",
    "        #     Transform(surface, surfaces[1]),\n",
    "        #     run_time=3\n",
    "        # )\n",
    "\n",
    "        # self.play(\n",
    "        #     Transform(surface, surfaces[2]),\n",
    "        #     # Move camera frame during the transition\n",
    "        #     frame.animate.increment_phi(-10 * DEGREES),\n",
    "        #     frame.animate.increment_theta(-20 * DEGREES),\n",
    "        #     run_time=3\n",
    "        # )\n",
    "        # # Add ambient rotation\n",
    "        # frame.add_updater(lambda m, dt: m.increment_theta(-0.1 * dt))\n",
    "\n",
    "        # # Play around with where the light is\n",
    "        # light_text = Text(\"You can move around the light source\")\n",
    "        # light_text.move_to(surface_text)\n",
    "        # light_text.fix_in_frame()\n",
    "\n",
    "        # self.play(FadeTransform(surface_text, light_text))\n",
    "        # light = self.camera.light_source\n",
    "        # self.add(light)\n",
    "        # light.save_state()\n",
    "        # self.play(light.animate.move_to(3 * IN), run_time=5)\n",
    "        # self.play(light.animate.shift(10 * OUT), run_time=5)\n",
    "\n",
    "        # drag_text = Text(\"Try moving the mouse while pressing d or s\")\n",
    "        # drag_text.move_to(light_text)\n",
    "        # drag_text.fix_in_frame()\n",
    "\n",
    "        # self.play(FadeTransform(light_text, drag_text))\n",
    "        # self.wait()\n",
    "\n",
    "        class TextExample(Scene):\n",
    "        def construct(self):\n",
    "        # To run this scene properly, you should have \"Consolas\" font in your computer\n",
    "        # for full usage, you can see https://github.com/3b1b/manim/pull/680\n",
    "        text = Text(\"Here is a text\", font=\"Consolas\", font_size=90)\n",
    "        difference = Text(\n",
    "            \"\"\"\n",
    "            The most important difference between Text and TexText is that\\n\n",
    "            you can change the font more easily, but can't use the LaTeX grammar\n",
    "            \"\"\",\n",
    "            font=\"Arial\", font_size=24,\n",
    "            # t2c is a dict that you can choose color for different text\n",
    "            t2c={\"Text\": BLUE, \"TexText\": BLUE, \"LaTeX\": ORANGE}\n",
    "        )\n",
    "        VGroup(text, difference).arrange(DOWN, buff=1)\n",
    "        self.play(Write(text))\n",
    "        self.play(FadeIn(difference, UP))\n",
    "        self.wait(3)\n",
    "\n",
    "        fonts = Text(\n",
    "            \"And you can also set the font according to different words\",\n",
    "            font=\"Arial\",\n",
    "            t2f={\"font\": \"Consolas\", \"words\": \"Consolas\"},\n",
    "            t2c={\"font\": BLUE, \"words\": GREEN}\n",
    "        )\n",
    "        fonts.set_width(FRAME_WIDTH - 1)\n",
    "        slant = Text(\n",
    "            \"And the same as slant and weight\",\n",
    "            font=\"Consolas\",\n",
    "            t2s={\"slant\": ITALIC},\n",
    "            t2w={\"weight\": BOLD},\n",
    "            t2c={\"slant\": ORANGE, \"weight\": RED}\n",
    "        )\n",
    "        VGroup(fonts, slant).arrange(DOWN, buff=0.8)\n",
    "        self.play(FadeOut(text), FadeOut(difference, shift=DOWN))\n",
    "        self.play(Write(fonts))\n",
    "        self.wait()\n",
    "        self.play(Write(slant))\n",
    "        self.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manim import *\n",
    "from manim_voiceover import VoiceoverScene\n",
    "from manim_voiceover.services.gtts import GTTSService\n",
    "# from manim_voiceover.services.coqui import CoquiService\n",
    "# from manim_voiceover.services.azure import AzureService\n",
    "\n",
    "class AL2(VoiceoverScene):\n",
    "    def construct(self):\n",
    "        self.set_speech_service(GTTSService(transcription_model='base'))\n",
    "        # self.set_speech_service(CoquiService(transcription_model='base'))\n",
    "         # self.set_speech_service(CoquiService(transcription_model='base'))\n",
    "        # self.set_speech_service(\n",
    "        #     AzureService(\n",
    "        #         voice=\"en-US-AriaNeural\",\n",
    "        #         style=\"newscast-casual\",\n",
    "        #     )\n",
    "        # )\n",
    "\n",
    "        title = Text(\"PSLV - C57 / ADITYA-L1 Mission\", font=\"Bookman Old Style\", color=WHITE,\n",
    "        t2c={\"ADITYA-L1\": ORANGE, \"Mission\": GRAY })\n",
    "\n",
    "        with self.voiceover(text=\"PSLV C57 ADITYA-L1 Mission\") as tracker:\n",
    "            self.play(Write(title), run_time = tracker.duration)\n",
    "\n",
    "## section About mission\n",
    "        subtitle_1 = Text(\n",
    "            \"\"\"\n",
    "            The First Observatory-class space-based solar\n",
    "            mission from India\n",
    "            \"\"\",\n",
    "            font=\"Bookman Old Style\", color=GRAY, font_size=34\n",
    "            # t2c is a dict that you can choose color for different text\n",
    "            # t2c={\"Text\": BLUE, \"TexText\": BLUE, \"LaTeX\": ORANGE}\n",
    "        )\n",
    "        subtitle_1.next_to(title, DOWN)\n",
    "\n",
    "        subtitle_2 = Text(\n",
    "            \"\"\"\n",
    "            PSLV-C57 is the 59th flight of PSLV and 25th mission using PSLV-XL configuration.\\n\n",
    "            It is planned from Second Launch Pad (SLP), SDSC, SHAR. PSLV-C57 will launch \\n\n",
    "            Aditya-L1 spacecraft in a highly eccentric Earth bound orbit. The spacecraft will \\n\n",
    "            perform orbital maneuvers by using its LAM to reach Sun-Earth Lagrange point Ll \\n\n",
    "            (1.5 million kilometers from Earth, in a halo orbit). \n",
    "            \"\"\",\n",
    "            font=\"Bookman Old Style\", color=GRAY, font_size=20\n",
    "            # t2c is a dict that you can choose color for different text\n",
    "            # t2c={\"Text\": BLUE, \"TexText\": BLUE, \"LaTeX\": ORANGE}\n",
    "        )\n",
    "        subtitle_2.next_to(title, DOWN)\n",
    "\n",
    "        with self.voiceover(text=\"The First Observatory class space based solar mission from India\") as tracker:\n",
    "            # self.play(Write(title), run_time = tracker.duration)\n",
    "            self.play(Write(subtitle_1))\n",
    "\n",
    "        self.play(FadeOut(subtitle_1, shift=DOWN))\n",
    "\n",
    "        with self.voiceover(text=\"PSLV-C57 is the 59th flight of PSLV. It will launch Aditya-L1 spacecraft in a highly eccentric Earth bound orbit to reach Sun-Earth Lagrange point Ll which is 1.5 million kilometers from Earth, in a halo orbit.\") as tracker:\n",
    "            self.play(Write(subtitle_2))\n",
    "\n",
    "        self.play(title.animate.to_edge(UP))\n",
    "        self.play(FadeOut(subtitle_2, shift=DOWN))\n",
    "\n",
    "## section TOC\n",
    "        \n",
    "        subtitle_toc = Text(\"Everything about Aditya L1 mission.\",\n",
    "            font=\"Bookman Old Style\", color=ORANGE)\n",
    "\n",
    "        with self.voiceover(text=\"In this video we will discuss What Why How Where and When of Aditya L1 Mission\") as tracker:\n",
    "            self.play(Write(subtitle_toc))\n",
    "\n",
    "        self.play(FadeOut(subtitle_toc))\n",
    "\n",
    "        titleNew = Text(\"About Earth\", font=\"Bookman Old Style\", color=WHITE,\n",
    "        t2c={\"About\": ORANGE, \"Earth\": BLUE })\n",
    "\n",
    "        with self.voiceover(text=\"Lets talk about what is happening?\") as tracker:\n",
    "            self.play(ReplacementTransform(title, titleNew))\n",
    "            self.play(titleNew.animate.to_edge(UP))\n",
    "\n",
    "## section About Earth\n",
    "        # earthImage = \"../SampleData/earth.jpg\"\n",
    "        # with self.voiceover(text=\"This is our home planet, known as Earth.\") as tracker:\n",
    "        #     self.play(FadeIn(ImageMobject(earthImage).scale(2)))\n",
    "\n",
    "        #     # axes = ThreeDAxes()\n",
    "        #     # arrow = Arrow3D(\n",
    "        #     #     start=np.array([0, 0, 0]),\n",
    "        #     #     end=np.array([2, 2, 2]),\n",
    "        #     #     resolution=8\n",
    "        #     # )\n",
    "        #     self.play(Rotating(img, run_time=2))\n",
    "        img = \"../SampleData/earth.jpg\"\n",
    "        earthImage = ImageMobject(img)\n",
    "        massText = Text(\"Mass = 5.9722×10^24 kg\", font=\"Bookman Old Style\", color=BLUE, font_size=28)\n",
    "        massText.next_to(earthImage, RIGHT, buff=0.2)\n",
    "        diaText = Text(\"Diameter = 12,756 km\", font=\"Bookman Old Style\", color=BLUE, font_size=28)\n",
    "        diaText.next_to(massText, DOWN, buff=0.2)\n",
    "        with self.voiceover(text=\"This is our home planet, known as Earth.\") as tracker:\n",
    "            self.play(FadeIn(earthImage.scale(2.5)))\n",
    "        \n",
    "        self.wait(1)\n",
    "        self.play(earthImage.animate.move_to(LEFT * 5))\n",
    "            # axes = ThreeDAxes()\n",
    "            # arrow = Arrow3D(\n",
    "            #     start=np.array([0, 0, 0]),\n",
    "            #     end=np.array([2, 2, 2]),\n",
    "            #     resolution=8\n",
    "            # )\n",
    "        with self.voiceover(text=\"Earth has a mass of 5.9722× 10 to power of 24 kg and diameter of 12,756 km.\") as tracker:\n",
    "            # self.play(FadeIn(earthImage.scale(4)))\n",
    "            # self.wait_until_bookmark('mass')\n",
    "            self.play(Write(massText))\n",
    "            # self.wait_until_bookmark(\"showdiam\")\n",
    "            self.play(Write(diaText))\n",
    "            \n",
    "\n",
    "        self.play(Rotating(earthImage, run_time=10))\n",
    "        ax= Axes()\n",
    "        sin = ax.plot(lambda x: np.sin(x), color=PURPLE_B)\n",
    "        label = ax.get_graph_label(\n",
    "            graph=sin,\n",
    "            label= Text(\"Test\"),\n",
    "            x_val=PI / 2,\n",
    "            dot=True,\n",
    "            direction=UR,\n",
    "        )\n",
    "        self.play(FadeOut(massText, diaText))\n",
    "        # self.add(ax, sin, label)\n",
    "        self.play(FadeIn(ax,sin,label))\n",
    "        self.wait(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%manim -ql AL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manim import *\n",
    "from manim_voiceover import VoiceoverScene\n",
    "from manim_voiceover.services.gtts import GTTSService\n",
    "\n",
    "class AL1(VoiceoverScene):\n",
    "    def construct(self):\n",
    "        self.set_speech_service(GTTSService())\n",
    "        img = \"../SampleData/earth.jpg\"\n",
    "        earthImage = ImageMobject(img)\n",
    "        massText = Text(\"M⊕ = 5.9722×10^24 kg\", font=\"Bookman Old Style\", color=ORANGE, font_size=24)\n",
    "        massText.next_to(earthImage, RIGHT, buff=2.0)\n",
    "        diaText = Text(\"D⊕ = 12,756 km\", font=\"Bookman Old Style\", color=ORANGE, font_size=24)\n",
    "        diaText.next_to(massText, DOWN, buff=1.0)\n",
    "        with self.voiceover(text=\"This is our home planet, known as Earth.\") as tracker:\n",
    "            self.play(FadeIn(earthImage.scale(4)))\n",
    "            self.wait(1)\n",
    "            self.play(earthImage.animate.scale(0.20).move_to(LEFT * 5))\n",
    "            # axes = ThreeDAxes()\n",
    "            # arrow = Arrow3D(\n",
    "            #     start=np.array([0, 0, 0]),\n",
    "            #     end=np.array([2, 2, 2]),\n",
    "            #     resolution=8\n",
    "            # )\n",
    "        with self.voiceover(text=\"Earth has a mass of 5.9722× 10 to power of 24 kg and diameter of 12,756 km.\") as tracker:\n",
    "            self.play(FadeIn(earthImage.scale(4)))\n",
    "            # self.wait_until_bookmark('mass')\n",
    "            self.play(Write(massText))\n",
    "            # self.wait_until_bookmark(\"showdiam\")\n",
    "            self.play(Write(diaText))\n",
    "            \n",
    "\n",
    "        self.play(Rotating(earthImage, run_time=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%manim -qm AL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manim import *\n",
    "class AL3(Scene):\n",
    "    def construct(self):\n",
    "        title = Text(\"PSLV - C57 / ADITYA-L1 Mission\", font=\"Bookman Old Style\", color=WHITE,\n",
    "        t2c={\"ADITYA-L1\": ORANGE, \"Mission\": GRAY })\n",
    "\n",
    "        self.add(title)\n",
    "\n",
    "## section About mission\n",
    "        subtitle_1 = Text(\n",
    "            \"\"\"\n",
    "            PSLV-C57 is the 59th flight of PSLV and 25th mission using PSLV-XL configuration.\\n\n",
    "            It is planned from Second Launch Pad (SLP), SDSC, SHAR. PSLV-C57 will launch \\n\n",
    "            Aditya-L1 spacecraft in a highly eccentric Earth bound orbit. The spacecraft will \\n\n",
    "            perform orbital maneuvers by using its LAM to reach Sun-Earth Lagrange point Ll \\n\n",
    "            (1.5 million kilometers from Earth, in a halo orbit). \n",
    "            \"\"\",\n",
    "            font=\"Bookman Old Style\", color=GRAY, font_size=20\n",
    "            # t2c is a dict that you can choose color for different text\n",
    "            # t2c={\"Text\": BLUE, \"TexText\": BLUE, \"LaTeX\": ORANGE}\n",
    "        )\n",
    "        subtitle_1.next_to(title, DOWN)\n",
    "        self.add(subtitle_1)\n",
    "        self.remove(subtitle_1)\n",
    "\n",
    "        img = \"../SampleData/earth.jpg\"\n",
    "        earthImage = ImageMobject(img)\n",
    "        self.play(FadeIn(earthImage.scale(2.5)))\n",
    "        self.wait(1)\n",
    "        self.play(earthImage.animate.move_to(LEFT * 5))\n",
    "        self.play(FadeOut(earthImage))\n",
    "\n",
    "        massText = Text(\"Mass = 5.9722×10^24 kg\", font=\"Bookman Old Style\", color=BLUE, font_size=28)\n",
    "        massText.next_to(earthImage, RIGHT, buff=0.2)\n",
    "        diaText = Text(\"Diameter = 12,756 km\", font=\"Bookman Old Style\", color=BLUE, font_size=28)\n",
    "        diaText.next_to(massText, DOWN, buff=0.2)\n",
    "\n",
    "        ax = Axes()\n",
    "\n",
    "        # self.add(earthImage, diaText, massText)\n",
    "        # self.remove(earthImage, diaText, massText)\n",
    "\n",
    "        sin = ax.plot(lambda x: np.sin(x), color=PURPLE_B)\n",
    "        label = ax.get_graph_label(\n",
    "            graph=sin,\n",
    "            label= Text(\"Test\"),\n",
    "            x_val=PI / 2,\n",
    "            dot=True,\n",
    "            direction=UR,\n",
    "        )\n",
    "\n",
    "        self.add(ax, sin, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%manim -ql AL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manim import *\n",
    "\n",
    "class MovingDots(Scene):\n",
    "    def construct(self):\n",
    "        img = \"../SampleData/earth.jpg\"\n",
    "        earthImage = ImageMobject(img)\n",
    "        self.play(FadeIn(earthImage.scale(5)))\n",
    "        d1,d2=Dot(color=BLUE),Dot(color=GREEN)\n",
    "        dg=VGroup(d1,d2).arrange(RIGHT,buff=7)\n",
    "        title = Text(\"PSLV - C57 / ADITYA-L1 Mission\", font=\"Bookman Old Style\", color=WHITE, font_size=14,\n",
    "        t2c={\"ADITYA-L1\": ORANGE, \"Mission\": GRAY })\n",
    "        title.next_to(dg, DOWN, buff=0.2)\n",
    "        title2 = Text(\"Mission Aditya PSLV - C57\", font=\"Bookman Old Style\", color=RED, font_size=14,\n",
    "        t2c={\"ADITYA-L1\": GREEN, \"Mission\": YELLOW })\n",
    "        title2.next_to(d2, DOWN, buff=0.2)\n",
    "        l1=Line(d1.get_center(),d2.get_center()).set_color(RED)\n",
    "        x=ValueTracker(0)\n",
    "        y=ValueTracker(0)\n",
    "        d1.add_updater(lambda z: z.set_x(x.get_value()))\n",
    "        d2.add_updater(lambda z: z.set_y(y.get_value()))\n",
    "        l1.add_updater(lambda z: z.become(Line(d1.get_center(),d2.get_center())))\n",
    "        self.add(d1,d2,l1)\n",
    "        self.play(x.animate.set_value(3), Write(title), run_time=3)\n",
    "        self.play(ReplacementTransform(title, title2))\n",
    "        # self.play(y.animate.set_value(4))\n",
    "        self.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%manim -ql MovingDots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manim import *\n",
    "class S2P(Scene):\n",
    "    def construct(self):\n",
    "        self.camera.background_color = \"#ffffff\"\n",
    "        img = \"../../../S2P.png\"\n",
    "        s2pImage = ImageMobject(img)\n",
    "        # img = \"..//../../ping2.png\"\n",
    "        # earthImage2 = ImageMobject(img)\n",
    "        # earthImage2.next_to(earthImage, direction=RIGHT, buff=0.2)\n",
    "        self.add(s2pImage.scale(1.15))\n",
    "        # self.wait(1)\n",
    "\n",
    "        dot71 = Dot([-6.1, -3.0, 0])\n",
    "        dot72 = Dot([-3.0, -3.0, 0])\n",
    "        line = Line(dot71.get_center(), dot72.get_center(), stroke_width=1).set_color(ORANGE)\n",
    "        b1 = Brace(line, color=ORANGE)\n",
    "\n",
    "        dot1 = Dot().set_color(YELLOW_D)\n",
    "        dot2 = Dot().set_color(BLUE)\n",
    "        dot3 = Dot().set_color(BLACK)\n",
    "        dot4 = Dot().set_color(BLACK)\n",
    "        dot5 = Dot().set_color(ORANGE)\n",
    "        dot6 = Dot().set_color(PINK)\n",
    "        self.add(dot1, dot2, dot3, dot4, dot5, dot6, dot71, dot72, line, b1)\n",
    "\n",
    "        line11 = Line(start=[-3.1, 1.3, 0], end=[-3.1, 2.1, 0], color=ORANGE, stroke_width=1)\n",
    "        line12 = Line(start=[-3.1, 2.1, 0], end=[-6.5, 2.1, 0], color=ORANGE, stroke_width=1)\n",
    "        line13 = Line(start=[-6.5, 2.1, 0], end=[-6.5, -0.6, 0], color=ORANGE, stroke_width=1)\n",
    "        line14 = Line(start=[-6.5, -0.6, 0], end=[-5.8, -0.6, 0], color=ORANGE, stroke_width=1)\n",
    "        gr1 = VGroup(line11, line12, line13, line14)\n",
    "        self.add(gr1)\n",
    "\n",
    "        line21 = Line(start=[-3.7, -0.8, 0], end=[-5.4, -0.8, 0], color=BLUE, stroke_width=1)\n",
    "        line22 = Line(start=[-3.9, -0.5, 0], end=[-5.4, 0.2, 0], color=BLUE, stroke_width=1)\n",
    "        gr2 = VGroup(line21, line22)\n",
    "        self.add(gr2)\n",
    "\n",
    "        line31 = Line(start=[-3.6, -0.8, 0], end=[-3.6, -3.8, 0], color=BLACK, stroke_width=1)\n",
    "        line32 = Line(start=[-3.6, -3.8, 0], end=[6.8, -3.8, 0], color=BLACK, stroke_width=1)\n",
    "        line33 = Line(start=[6.8, -3.8, 0], end=[6.8, 0.0, 0], color=BLACK, stroke_width=1)\n",
    "        line34 = Line(start=[6.8, 0.0, 0], end=[4.8, 0.0, 0], color=BLACK, stroke_width=1)\n",
    "        gr3 = VGroup(line31, line32, line33, line34)\n",
    "        self.add(gr3)\n",
    "\n",
    "        line41 = Line(start=[-0.4, -2.4, 0], end=[-0.4, -5.0, 0], color=BLACK, stroke_width=1)\n",
    "        line42 = Line(start=[-0.6, -5.0, 0], end=[-0.6, -2.4, 0], color=BLACK, stroke_width=1)\n",
    "        gr4 = VGroup(line41, line42)\n",
    "        self.add(gr4)\n",
    "\n",
    "        line51 = Line(start=[-6.3, 1.1, 0], end=[-6.9, 1.1, 0], color=PURPLE, stroke_width=1)\n",
    "        line52 = Line(start=[-6.9, 1.1, 0], end=[-6.9, -3.8, 0], color=PURPLE, stroke_width=1)\n",
    "        line53 = Line(start=[-6.9, -3.8, 0], end=[4.8, -3.8, 0], color=PURPLE, stroke_width=1)\n",
    "        line54 = Line(start=[4.8, -3.8, 0], end=[4.8, 0.0, 0], color=PURPLE, stroke_width=1)\n",
    "        gr5 = VGroup(line51, line52, line53, line54)\n",
    "        self.add(gr5)\n",
    "\n",
    "        line61 = Line(start=[-6.1, -0.8, 0], end=[-6.8, -0.8, 0], color=PURPLE, stroke_width=1)\n",
    "        line62 = Line(start=[-6.8, -0.8, 0], end=[-6.8, -3.5, 0], color=PURPLE, stroke_width=1)\n",
    "        line63 = Line(start=[-6.8, -3.5, 0], end=[5.0, -3.5, 0], color=PURPLE, stroke_width=1)\n",
    "        line64 = Line(start=[5.0, -3.5, 0], end=[5.0, 0.0, 0], color=PURPLE, stroke_width=1)\n",
    "        gr6 = VGroup(line61, line62, line63, line64)\n",
    "        self.add(gr6)\n",
    "\n",
    "        # self.play(Transform(dot, dot2))\n",
    "        self.play(MoveAlongPath(dot1, line11), MoveAlongPath(dot2, line21), MoveAlongPath(dot3, line31), MoveAlongPath(dot4, line41), MoveAlongPath(dot5, line51), MoveAlongPath(dot6, line61))\n",
    "        self.play(MoveAlongPath(dot1, line12), MoveAlongPath(dot2, line22), MoveAlongPath(dot3, line32), MoveAlongPath(dot4, line42), MoveAlongPath(dot5, line52), MoveAlongPath(dot6, line62))\n",
    "        self.play(MoveAlongPath(dot1, line13), MoveAlongPath(dot2, line21), MoveAlongPath(dot3, line33), MoveAlongPath(dot4, line41), MoveAlongPath(dot5, line53), MoveAlongPath(dot6, line63))\n",
    "        self.play(MoveAlongPath(dot1, line14), MoveAlongPath(dot2, line22), MoveAlongPath(dot3, line34), MoveAlongPath(dot4, line42), MoveAlongPath(dot5, line54), MoveAlongPath(dot6, line64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%manim -ql S2P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.organization = \"org-wDk1StTh2q8An7BShjzr6zJF\"\n",
    "\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\") # setup windows environment variable\n",
    "openai.api_key = \"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\" # setup windows environment variable\n",
    "# model_engine = \"gpt-3.5-turbo\"\n",
    "# model_engine = \"text-davinci-003\"\n",
    "model_engine = \"GPT-4\"\n",
    "openai.Model.list()\n",
    "\n",
    "# completion = openai.ChatCompletion.create(\n",
    "#   model=model_engine,\n",
    "#   messages=[\n",
    "#     {\"role\": \"user\", \"content\": \"rephrase: I also need an environment (high end machine with more storage) which I can use to schedule BOTs in parallel,These BOTs currently run on 1-2 Laptop machines which slows down data extraction. Storage and transmission.Having a high end Snowflake or Oracle like Data Lake environment, will help me expedite data extraction, reconciliation and transmission.\"}\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py -m pip install pytesseract\n",
    "# py -m pip install PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# py -m pip install pytesseract\n",
    "# py -m pip install PIL\n",
    "\n",
    "# make sure, you have tesseract included in your environment path\n",
    "import os\n",
    "os.getenv(\"tesseract\")\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "##############################################################################\n",
    "# in case if tesseract is not included in PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\amit.la\\WIP\\RPA\\downloads\\ts\\tesseract.exe'\n",
    "##############################################################################\n",
    "\n",
    "def read_image_text(image_path):\n",
    "    \"\"\"\n",
    "    Reads text from an image file using Tesseract OCR.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the input image.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted text from the image.\n",
    "    \"\"\"\n",
    "    # Load the image file\n",
    "    image = Image.open(image_path)\n",
    "    # Use Tesseract OCR to extract the text from the image\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "image_path = \"../downloads/medical_form.png\"\n",
    "text = read_image_text(image_path)\n",
    "print(text)\n",
    "\n",
    "# ## below code is to tabulate data - NA - here\n",
    "# from tabulate import tabulate\n",
    "\n",
    "# # Example text data\n",
    "# text_data = \"\"\"\n",
    "# Name        Age     Occupation\n",
    "# Alice       25      Engineer\n",
    "# Bob         30      Developer\n",
    "# Charlie     40      Manager\n",
    "# \"\"\"\n",
    "\n",
    "# # Split the text into rows and columns\n",
    "# rows = [row.strip().split() for row in text_data.strip().split(\"\\n\")]\n",
    "# # Create the table using the tabulate library\n",
    "# table = tabulate(rows, headers=\"firstrow\")\n",
    "# # Print the table\n",
    "# print(table)\n",
    "# ## above code just tabulate data - NA - here\n",
    "\n",
    "###########################################\n",
    "# Send prompts to Llama 2 | ChatGPT\n",
    "###########################################\n",
    "\n",
    "def callChatGPT(prompt):\n",
    "    ###########################################\n",
    "    # uncomment this code to call ChatGPT API #\n",
    "    ###########################################\n",
    "    # completion = openai.ChatCompletion.create(\n",
    "    # model=model_engine,\n",
    "    # messages=[\n",
    "    #     {\"role\": \"user\", \"content\": prompt}\n",
    "    # ])\n",
    "    # return completion.choices[0].message.content\n",
    "\n",
    "def callLlama(prompt):\n",
    "    ###########################################\n",
    "    # uncomment this code to call Llama API #\n",
    "    ###########################################\n",
    "    # results = generator.chat_completion(\n",
    "    #     dialogs,  # type: ignore\n",
    "    #     max_gen_len=max_gen_len,\n",
    "    #     temperature=temperature,\n",
    "    #     top_p=top_p,\n",
    "    # )\n",
    "    # return result['generation']['content']\n",
    "\n",
    "# build dynamic prompt per use case\n",
    "\n",
    "def callChatGPT(prompt):\n",
    "    import os\n",
    "    import openai\n",
    "    openai.organization = \"org-xxx\"\n",
    "\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\") # setup windows environment variable\n",
    "    # model_engine = \"gpt-3.5-turbo\"\n",
    "    # model_engine = \"text-davinci-003\"\n",
    "    # model_engine = \"GPT-4\"\n",
    "    # openai.Model.list()\n",
    "\n",
    "    # completion = openai.ChatCompletion.create(\n",
    "    #   model=model_engine,\n",
    "    #   messages=[\n",
    "    #     {\"role\": \"user\", \"content\": \"rephrase: {prompt}\"}\n",
    "    #   ]\n",
    "    # )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "    # print(completion.choices[0].message.content)\n",
    "\n",
    "prompt = \"respond in one word: total number of hours in timesheet.\"\n",
    "# prompt = \"respond in one word: total number of hours regular hours.\"\n",
    "# prompt = \"respond in one word: total number of hours overtime hours.\"\n",
    "# prompt = \"don't do any math, just look for hours column and add hours. respond in one word: total number of hours in timesheet.\"\n",
    "# prompt = \"ignore time in and time out. don't do any math, just look for hours column and add hours. respond in one word: total number of hours in timesheet.\"\n",
    "\n",
    "prompt += promptText\n",
    "\n",
    "### NO FINE TUNING Is DONE on ChatGPT Plus ###\n",
    "### by passing 1-2 invoice image contents to Llama2, aka FINE TUNING on Llama2 is working good. ###\n",
    "### I am sure, fine tuning will improve on results ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
