{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Time and Expense Monitoring with Llama 2\n",
    "---\n",
    "\n",
    "    Author: Amit Shukla\n",
    "\n",
    "[https://github.com/AmitXShukla](https://github.com/AmitXShukla)\n",
    "\n",
    "[https://twitter.com/ashuklax](https://github.com/AShuklaX)\n",
    "\n",
    "[https://youtube.com/@Amit.Shukla](https://youtube.com/@Amit.Shukla)\n",
    "\n",
    "\n",
    "Meta has recently released Llama 2, a large language model trained with up to 70B parameters, positioning it as the fastest and most advanced solution available. This model is expected to outperform other tools in terms of both speed and accuracy.\n",
    "\n",
    "In this blog post, I will demonstrate some automation use cases I have been working on. \n",
    "\n",
    "It's important to note that these use cases/models will work best when trained on \"in-house\" data. However, training such models is a rigorous task that requires significant computing hours and resources.\n",
    "\n",
    "To make things more accessible and easier to utilize in production, using \"off the shelf\", language models like ChatGPT and Llama 2 is a viable solution.\n",
    "\n",
    "Below, I present some examples of use cases I've been working on. \n",
    "\n",
    "*While these examples are not meant for production*, they still showcase the powerful capabilities of the language models.\n",
    "\n",
    "`Upon completing this blog, you will acquire the skills to build Llama 2 and ChatGPT APIs and harness the capabilities of large language models for practical data analytics tasks.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "---\n",
    "\n",
    "- Introduction\n",
    "- [Llama 2 Installation Windows/Linux](https://github.com/AmitXShukla/RPA/blob/main/notebooks/llama2-UseCases.ipynb)\n",
    "- [Efficient Time and Expense Monitoring with Llama 2](https://github.com/AmitXShukla/RPA/blob/main/notebooks/llama2-Efficient%20Time%20and%20Expense%20Monitoring%20with%20Llama%202.ipynb)\n",
    "- [Using Llama 2 as OCR Vision AI](https://github.com/AmitXShukla/RPA/blob/main/notebooks/llama2-Using%20Llama%202%20as%20OCR%20Vision%20AI.ipynb)\n",
    "- [Llama 2 as Supply Chain Assistant](https://github.com/AmitXShukla/RPA/blob/main/notebooks/llama2-as%20Supply%20Chain%20assistant.ipynb)\n",
    "    - Streamlining 3-Way Receipt Match and Duplicate Voucher Invoices with Llama 2\n",
    "    - Enhancing Fraud Detection: Utilizing Llama 2 as an Advanced Alert System for Monitoring Transactions\n",
    "    - Maximizing Tax Savings, Ensuring Compliance, and Streamlining Audits with Llama 2\n",
    "-  `**WIP**`: Tax Analytics | Spend Classification | Contracts management\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About me\n",
    "I'm Amit Shukla, and I specialize in training neural networks for Finance Supply Chain analysis, enabling them to identify data patterns and make accurate predictions.\n",
    "\n",
    "During the challenges posed by the COVID-19 pandemic, I successfully trained GL and Supply Chain neural networks to anticipate supply chain shortages. The valuable insights gained from this effort have significantly influenced the content of this tutorial series.\n",
    "\t\n",
    "#### Objective:\n",
    "By delving into this powerful tool, we will master the fundamental techniques of utilizing large language models to predict hazards. \n",
    "This knowledge is crucial in preparing finance and supply chain data for advanced analytics, visualization, and predictive modeling using neural networks and machine learning.\n",
    "\t\n",
    "#### Subject\n",
    "It is crucial to emphasize that this specific series will focus exclusively on presenting `production-like examples that demonstrate certain use cases`. It is not intended for production applications. \n",
    "\n",
    "Nevertheless, these examples illustrate highly potent techniques that have practical applications in real-world Data Analytics.\n",
    "\t\n",
    "#### Following\n",
    "In future installments, we will explore Data Analytics and delve into the realm of Data Analytics and machine learning for predictive analytics.\n",
    "\n",
    "Thank you for joining me, and I'm excited to embark on this educational journey together.\n",
    "\t\n",
    "Let's get started.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous video, I demonstrated the process of activating the Open ChatGPT and Llama environments. \n",
    "\n",
    "In this section, I will guide you through the steps to install Llama 2 on a Windows operating system. \n",
    "\n",
    "While the installation process is quite similar to that on Linux, there are a few minor changes that need to be considered. \n",
    "\n",
    "Let's get started!\n",
    "\n",
    "- Step 1: `download miniconda windows installer` [https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)\n",
    "- Step 2: create a new conda environment (say llamaConda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before you setup your machine for llama 2, check if you have cuda on your machine\n",
    "\n",
    "import torch\n",
    "torch.cuda.current_device()\n",
    "# if you don't have cuda and torch on your machine, please move to next step and download cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pytorch cuda\n",
    "# https://pytorch.org/get-started/locally/\n",
    "# uncomment and run this command in Terminal to monitor download progress and debug any error\n",
    "\n",
    "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'Quadro RTX 4000')"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run these command again and make sure you have cuda available on your machine\n",
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.is_available(),torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this case if you see CUDA out of memory error\n",
    "# also, try to reduce your << --max_batch_size 1 >>, max_split_size_mb:512 and work with \"lowest memory size\" model\n",
    "# !torchrun --nproc_per_node 1 example_text_completion.py --ckpt_dir llama-2-7b --tokenizer_path tokenizer.model --max_seq_len 512 --max_batch_size 1\n",
    "# clear cache\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:24\"\n",
    "\n",
    "# import gc\n",
    "# del variables\n",
    "# gc.collect()\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "signup and receive model download link from meta.\n",
    "\n",
    "[Mete AI website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)\n",
    ">>>\n",
    "    do not use the 'Copy link address' option when you right click the URL. If the copied URL text starts with: https://download.llamameta.net, you copied it correctly. If the copied URL text starts with: https://l.facebook.com, you copied it the wrong way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: uncomment and run this command on your machine\n",
    "# make sure, you have a Git installed on your machine if not\n",
    "# for linux run \n",
    "# sudo apt install git-all\n",
    "\n",
    "# for windows, download git from this link\n",
    "# https://git-scm.com/download/win\n",
    "\n",
    "####### clone Meta llama repo ##########\n",
    "git clone https://github.com/facebookresearch/llama.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browse to root of your llama repo\n",
    "\n",
    "## LINUX\n",
    "# cd llama\n",
    "# chmod +x # ./download.sh\n",
    "# ./download.sh\n",
    "\n",
    "## WINDOWS\n",
    "# bash ./download.sh\n",
    "# if this commands error out, download wget.exe from below link and copy wget.ex to C:\\amit.la\\llama\n",
    "# https://eternallybored.org/misc/wget/\n",
    "# make sure, you include << C:\\amit.la\\llama >> to windows environment path so that windows can find it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure, latest conda env is selected as kernel\n",
    "# before activating and installing dependencies\n",
    "\n",
    "!pip install -e .\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for windows\n",
    "# change line #62 on llama/generate.py\n",
    "# from \n",
    "# << torch.distributed.init_process_group(\"gloo|nccl\") >>\n",
    "# to\n",
    "# << torch.distributed.init_process_group(\"gloo|nccl\") >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure, latest conda env (llamaConda) is selected as kernel\n",
    "# before activating and installing dependencies\n",
    "\n",
    "# !pip install -e .\n",
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./example_text_completion.py\n",
    "# ./example_chat_completion.py\n",
    "\n",
    "# change prompts | dialogue \n",
    "#   prompts = [\n",
    "#         # For these prompts, the expected answer is the natural continuation of the prompt\n",
    "#         \"meaning of life is\",\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you are ready to use llama\n",
    "# !torchrun --nproc_per_node 1 example_text_completion.py --ckpt_dir llama-2-7b --tokenizer_path tokenizer.model --max_seq_len 512 --max_batch_size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Time and Expense Monitoring with Llama 2\n",
    "---\n",
    "\n",
    "#### Time card monitoring\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U polars # data warehouse\n",
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>AS_OF_DATE</th><th>EMPLOYEE_ID</th><th>MON</th><th>TUE</th><th>WED</th><th>THU</th><th>FRI</th></tr><tr><td>datetime[ms]</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>2022-01-01 00:00:00</td><td>1000</td><td>8</td><td>8</td><td>8</td><td>8</td><td>8</td></tr><tr><td>2022-01-02 00:00:00</td><td>1000</td><td>8</td><td>8</td><td>8</td><td>8</td><td>8</td></tr><tr><td>2022-01-03 00:00:00</td><td>1000</td><td>8</td><td>8</td><td>8</td><td>8</td><td>8</td></tr><tr><td>2022-01-04 00:00:00</td><td>1000</td><td>8</td><td>8</td><td>8</td><td>8</td><td>8</td></tr><tr><td>2022-01-05 00:00:00</td><td>1000</td><td>8</td><td>8</td><td>8</td><td>8</td><td>8</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────────────────┬─────────────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ AS_OF_DATE          ┆ EMPLOYEE_ID ┆ MON ┆ TUE ┆ WED ┆ THU ┆ FRI │\n",
       "│ ---                 ┆ ---         ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- │\n",
       "│ datetime[ms]        ┆ i64         ┆ i64 ┆ i64 ┆ i64 ┆ i64 ┆ i64 │\n",
       "╞═════════════════════╪═════════════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 2022-01-01 00:00:00 ┆ 1000        ┆ 8   ┆ 8   ┆ 8   ┆ 8   ┆ 8   │\n",
       "│ 2022-01-02 00:00:00 ┆ 1000        ┆ 8   ┆ 8   ┆ 8   ┆ 8   ┆ 8   │\n",
       "│ 2022-01-03 00:00:00 ┆ 1000        ┆ 8   ┆ 8   ┆ 8   ┆ 8   ┆ 8   │\n",
       "│ 2022-01-04 00:00:00 ┆ 1000        ┆ 8   ┆ 8   ┆ 8   ┆ 8   ┆ 8   │\n",
       "│ 2022-01-05 00:00:00 ┆ 1000        ┆ 8   ┆ 8   ┆ 8   ┆ 8   ┆ 8   │\n",
       "└─────────────────────┴─────────────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TIMECARD DataFrame ##\n",
    "## TEST Data ##\n",
    "from datetime import datetime, timedelta\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "dfTimeCard = pl.DataFrame({\n",
    "    'AS_OF_DATE': pl.date_range(datetime(2022, 1, 1), datetime(2023, 7, 20), timedelta(days=1), time_unit=\"ms\", eager=True),\n",
    "    \"EMPLOYEE_ID\": 1000,\n",
    "    \"MON\" : 8,\n",
    "    \"TUE\" : 8,\n",
    "    \"WED\" : 8,\n",
    "    \"THU\" : 8,\n",
    "    \"FRI\" : 8\n",
    "})\n",
    "\n",
    "for i in range(1001,2001,1):\n",
    "    timeCardTmp = pl.DataFrame({\n",
    "    'AS_OF_DATE': pl.date_range(datetime(2022, 1, 1), datetime(2023, 7, 20), timedelta(days=1), time_unit=\"ms\", eager=True),\n",
    "    \"EMPLOYEE_ID\": i,\n",
    "    \"MON\" : 8,\n",
    "    \"TUE\" : 8,\n",
    "    \"WED\" : 8,\n",
    "    \"THU\" : 8,\n",
    "    \"FRI\" : 8\n",
    "    })\n",
    "    dfTimeCard = pl.concat(\n",
    "    [\n",
    "        dfTimeCard,\n",
    "        timeCardTmp,\n",
    "    ],\n",
    "    how=\"vertical\",\n",
    "    )\n",
    "\n",
    "dfTimeCard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>MON</th><th>TUE</th><th>WED</th><th>THU</th><th>FRI</th><th>total</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;mean&quot;</td><td>8.01407</td><td>8.0</td><td>8.0</td><td>8.0</td><td>8.0</td><td>40.01407</td></tr><tr><td>&quot;min&quot;</td><td>8.0</td><td>8.0</td><td>8.0</td><td>8.0</td><td>8.0</td><td>40.0</td></tr><tr><td>&quot;max&quot;</td><td>12.0</td><td>8.0</td><td>8.0</td><td>8.0</td><td>8.0</td><td>44.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 7)\n",
       "┌──────────┬─────────┬─────┬─────┬─────┬─────┬──────────┐\n",
       "│ describe ┆ MON     ┆ TUE ┆ WED ┆ THU ┆ FRI ┆ total    │\n",
       "│ ---      ┆ ---     ┆ --- ┆ --- ┆ --- ┆ --- ┆ ---      │\n",
       "│ str      ┆ f64     ┆ f64 ┆ f64 ┆ f64 ┆ f64 ┆ f64      │\n",
       "╞══════════╪═════════╪═════╪═════╪═════╪═════╪══════════╡\n",
       "│ mean     ┆ 8.01407 ┆ 8.0 ┆ 8.0 ┆ 8.0 ┆ 8.0 ┆ 40.01407 │\n",
       "│ min      ┆ 8.0     ┆ 8.0 ┆ 8.0 ┆ 8.0 ┆ 8.0 ┆ 40.0     │\n",
       "│ max      ┆ 12.0    ┆ 8.0 ┆ 8.0 ┆ 8.0 ┆ 8.0 ┆ 44.0     │\n",
       "└──────────┴─────────┴─────┴─────┴─────┴─────┴──────────┘"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## collect standard stats from all dataset\n",
    "\n",
    "# dfTimeCard.describe()\n",
    "\n",
    "dayCols = [\"MON\",\"TUE\",\"WED\",\"THU\",\"FRI\"]\n",
    "## average, min, max and total hours per week in dataset\n",
    "dfTimeCardStats = dfTimeCard.describe().select(\n",
    "        pl.col(\"*\").exclude(\n",
    "            \"AS_OF_DATE\",\"EMPLOYEE_ID\")).filter(\n",
    "                (pl.col(\"describe\") == \"mean\") \n",
    "                | (pl.col(\"describe\") == \"max\") \n",
    "                | (pl.col(\"describe\") == \"min\")\n",
    "        ).select([\n",
    "        pl.col(\"*\"),\n",
    "        pl.sum_horizontal(dayCols).alias('total')\n",
    "    ])\n",
    "# dfTimeCardStats.item(0,6)\n",
    "dfTimeCardStats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>AS_OF_DATE</th><th>EMPLOYEE_ID</th><th>MON</th><th>TUE</th><th>WED</th><th>THU</th><th>FRI</th></tr><tr><td>datetime[ms]</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>2023-07-20 00:00:00</td><td>1001</td><td>8</td><td>8</td><td>8</td><td>8</td><td>8</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 7)\n",
       "┌─────────────────────┬─────────────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ AS_OF_DATE          ┆ EMPLOYEE_ID ┆ MON ┆ TUE ┆ WED ┆ THU ┆ FRI │\n",
       "│ ---                 ┆ ---         ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- │\n",
       "│ datetime[ms]        ┆ i64         ┆ i64 ┆ i64 ┆ i64 ┆ i64 ┆ i64 │\n",
       "╞═════════════════════╪═════════════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 2023-07-20 00:00:00 ┆ 1001        ┆ 8   ┆ 8   ┆ 8   ┆ 8   ┆ 8   │\n",
       "└─────────────────────┴─────────────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting latest stats by employee\n",
    "out = dfTimeCard.filter((pl.col(\"EMPLOYEE_ID\") == 1001) & (pl.col(\"AS_OF_DATE\") == datetime(2023, 7, 20)))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568566, 7)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's assume, today's time sheet is entered by all employees\n",
    "# and some of the employee accidentally booked 12 hours in a day\n",
    "\n",
    "for i in range(1001,2001,1):\n",
    "    timeCardTmp = pl.DataFrame({\n",
    "    'AS_OF_DATE': pl.date_range(datetime(2023, 7, 21), datetime(2023, 7, 22), timedelta(days=1), time_unit=\"ms\", eager=True),\n",
    "    \"EMPLOYEE_ID\": i,\n",
    "    \"MON\" : 12,\n",
    "    \"TUE\" : 8,\n",
    "    \"WED\" : 8,\n",
    "    \"THU\" : 8,\n",
    "    \"FRI\" : 8\n",
    "    })\n",
    "    dfTimeCard = pl.concat(\n",
    "    [\n",
    "        dfTimeCard,\n",
    "        timeCardTmp,\n",
    "    ],\n",
    "    how=\"vertical\",\n",
    "    )\n",
    "\n",
    "dfTimeCard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>AS_OF_DATE</th><th>EMPLOYEE_ID</th><th>MON</th><th>TUE</th><th>WED</th><th>THU</th><th>FRI</th></tr><tr><td>datetime[ms]</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>2023-07-21 00:00:00</td><td>1001</td><td>12</td><td>8</td><td>8</td><td>8</td><td>8</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 7)\n",
       "┌─────────────────────┬─────────────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ AS_OF_DATE          ┆ EMPLOYEE_ID ┆ MON ┆ TUE ┆ WED ┆ THU ┆ FRI │\n",
       "│ ---                 ┆ ---         ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- │\n",
       "│ datetime[ms]        ┆ i64         ┆ i64 ┆ i64 ┆ i64 ┆ i64 ┆ i64 │\n",
       "╞═════════════════════╪═════════════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 2023-07-21 00:00:00 ┆ 1001        ┆ 12  ┆ 8   ┆ 8   ┆ 8   ┆ 8   │\n",
       "└─────────────────────┴─────────────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting latest stats by employee\n",
    "out = dfTimeCard.filter((pl.col(\"EMPLOYEE_ID\") == 1001) & (pl.col(\"AS_OF_DATE\") == datetime(2023, 7, 21)))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST DATA Prompts ##\n",
    "# respond in one word, is there an anomaly in this data.\n",
    "# find anomalies in this data. \n",
    "\n",
    "# Record 1\n",
    "# My average working hours are 45 hours per week.\n",
    "# this week, I charged 45 hours this week.\n",
    "# I worked max 34 hours in one day. \n",
    "# I worked min 2 hours in one day, I also took 2 days PTO.\n",
    "\n",
    "# Record 2\n",
    "# My average working hours are 45 hours per week.\n",
    "# this week, I charged 45 hours this week.\n",
    "# I worked max 34 hours in one day. \n",
    "# I worked min 2 hours in one day, I also took 2 days PTO.\n",
    "\n",
    "# Record 3\n",
    "# My average working hours are 45 hours per week.\n",
    "# this week, I charged 45 hours this week.\n",
    "# I worked max 34 hours in one day. \n",
    "# I worked min 2 hours in one day, I also took 2 days PTO.\n",
    "\n",
    "# Record 4\n",
    "# My average working hours are 45 hours per week.\n",
    "# this week, I charged 45 hours this week.\n",
    "# I worked max 9 hours in one day. \n",
    "# I worked min 9 hours in one day, I also took 3 days PTO.\n",
    "\n",
    "# Record 5\n",
    "# respond in one word, is there an anomaly in this data.\n",
    "# My average working hours are 45 hours per week.\n",
    "# this week, I charged 36 hours this week.\n",
    "# I worked max 9 hours in one day. \n",
    "# I worked min 9 hours in one day, I also took 1 days PTO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'respond in one word, is there an anomaly in this data. Average employee working hours are 40.01407048610012 hours per week. This week, I charged total 44 hours. I worked 12,8,8,8,8, hours per day from Monday to Friday and took 0 PTOs'"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = dfTimeCard.filter((pl.col(\"EMPLOYEE_ID\") == 1001) & (pl.col(\"AS_OF_DATE\") == datetime(2023, 7, 21)))\n",
    "# out.head()\n",
    "\n",
    "prompt = \"respond in one word, is there an anomaly in this data. Average employee working hours are \" + str(dfTimeCardStats.item(0,6)) + \" hours per week. \"\n",
    "prompt += \"This week, I charged total \" + str(out.item(0,2) + out.item(0,3) + out.item(0,4) + out.item(0,5) + out.item(0,6)) + \" hours. \"\n",
    "prompt += \"I worked \" +str(out.item(0,2)) + \",\"+str(out.item(0,3)) + \",\"+str(out.item(0,4)) + \",\"+str(out.item(0,5)) + \",\"+str(out.item(0,6)) + \",\"\n",
    "prompt += \" hours per day from Monday to Friday and took 0 PTOs\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee ID 1001 has discrepancies in 2023-07-20 00:00:00 time sheet.\n",
      "Employee ID 1002 has discrepancies in 2023-07-20 00:00:00 time sheet.\n"
     ]
    }
   ],
   "source": [
    "# build dynamic prompt per day per employee\n",
    "timeCardDate = datetime(2023, 7, 20)\n",
    "\n",
    "for i in range(1001,1003,1):\n",
    "    out = dfTimeCard.filter((pl.col(\"EMPLOYEE_ID\") == i) & (pl.col(\"AS_OF_DATE\") == timeCardDate))\n",
    "    # out.head()\n",
    "\n",
    "    prompt = \"respond in one word, is there an anomaly in this data. Average employee working hours are \" + str(dfTimeCardStats.item(0,6)) + \" hours per week. \"\n",
    "    prompt += \"This week, I charged total \" + str(out.item(0,2) + out.item(0,3) + out.item(0,4) + out.item(0,5) + out.item(0,6)) + \" hours. \"\n",
    "    prompt += \"I worked \" +str(out.item(0,2)) + \",\"+str(out.item(0,3)) + \",\"+str(out.item(0,4)) + \",\"+str(out.item(0,5)) + \",\"+str(out.item(0,6)) + \",\"\n",
    "    prompt += \" hours per day from Monday to Friday and took 0 PTOs\"\n",
    "    \n",
    "    if callLlama(prompt) == \"Yes\":\n",
    "        print(f\"Employee ID {i} has discrepancies in {timeCardDate} time sheet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callChatGPT(prompt):\n",
    "    # completion = openai.ChatCompletion.create(\n",
    "    # model=model_engine,\n",
    "    # messages=[\n",
    "    #     {\"role\": \"user\", \"content\": prompt}\n",
    "    # ])\n",
    "    # return completion.choices[0].message.content\n",
    "    return \"Yes\"\n",
    "\n",
    "def callLlama(prompt):\n",
    "    # results = generator.chat_completion(\n",
    "    #     dialogs,  # type: ignore\n",
    "    #     max_gen_len=max_gen_len,\n",
    "    #     temperature=temperature,\n",
    "    #     top_p=top_p,\n",
    "    # )\n",
    "    # return result['generation']['content']\n",
    "    return \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expense monitoring\n",
    "---\n",
    "\n",
    "The process of handling expenses can be quite complex, involving numerous factors. \n",
    "\n",
    "In the following use case, I will illustrate one specific scenario where Llama can be employed to detect anomalies.\n",
    "\n",
    "However, please note that this is just one of the numerous examples demonstrating how Llama can be utilized for identifying irregularities.\n",
    "\n",
    "`For now, we haven't incorporated \"Images\" into the process. In upcoming tutorials, I will explain how you can utilize Llama to monitor expense images for potential fraud. `\n",
    "\n",
    "Let's consider a situation where employees are reimbursed based on their receipts, and a detailed record of items is maintained in a system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expense DataFrame ##\n",
    "## TEST Data ##\n",
    "from datetime import datetime, timedelta\n",
    "import polars as pl\n",
    "import random\n",
    "\n",
    "dfExpCard = pl.DataFrame({\n",
    "    'AS_OF_DATE': random.choices(pl.date_range(datetime(2022, 1, 1), datetime(2023, 7, 20), timedelta(days=1), time_unit=\"ms\", eager=True), k=1),\n",
    "    \"WEEKDAY\": random.choices((True, False), k=1),\n",
    "    \"EMPLOYEE_ID\": 1000,\n",
    "    \"EXPENSE_TYPE\" : random.choices([\"Lodging\", \"Meal\", \"Transit\", \"Air Ticket\", \"Group Lunch\", \"Office Supplies\"], k=1),\n",
    "    \"AMOUNT\" : random.randint(125, 955),\n",
    "    \"LOCATION\": random.choices([\"Reno\", \"Las Vegas\", \"Seattle\", \"Los Angeles\", \"New York\", \"San Francisco\"], k=1),\n",
    "    \"JUSTIFICATION\" : \"Hotels were sold out due to concert in area.\",\n",
    "})\n",
    "\n",
    "for i in range(1001,2001,1):\n",
    "    for j in range(1,11,1):\n",
    "        dfExpCardTmp = pl.DataFrame({\n",
    "        'AS_OF_DATE': random.choices(pl.date_range(datetime(2022, 1, 1), datetime(2023, 7, 20), timedelta(days=1), time_unit=\"ms\", eager=True), k=1),\n",
    "        \"WEEKDAY\": random.choices((True, False), k=1),\n",
    "        \"EMPLOYEE_ID\": i,\n",
    "        \"EXPENSE_TYPE\" : random.choices([\"Lodging\",\"Meal\", \"Transit\", \"Air Ticket\", \"Group Lunch\", \"Office Supplies\"], k=1),\n",
    "        \"AMOUNT\" : random.randint(125, 955),\n",
    "        \"LOCATION\": random.choices([\"Reno\", \"Las Vegas\", \"Seattle\", \"Los Angeles\", \"New York\", \"San Francisco\"], k=1),\n",
    "        \"JUSTIFICATION\" : \"Hotels were sold out due to concert in area.\",\n",
    "        })\n",
    "        dfExpCard = pl.concat(\n",
    "        [\n",
    "            dfExpCard,\n",
    "            dfExpCardTmp,\n",
    "        ],\n",
    "        how=\"vertical\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>AS_OF_DATE</th><th>WEEKDAY</th><th>EMPLOYEE_ID</th><th>EXPENSE_TYPE</th><th>AMOUNT</th><th>LOCATION</th><th>JUSTIFICATION</th></tr><tr><td>datetime[μs]</td><td>bool</td><td>i64</td><td>str</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2023-01-23 00:00:00</td><td>false</td><td>1000</td><td>&quot;Lodging&quot;</td><td>955</td><td>&quot;New York&quot;</td><td>&quot;Hotels were so…</td></tr><tr><td>2022-10-03 00:00:00</td><td>true</td><td>1001</td><td>&quot;Group Lunch&quot;</td><td>714</td><td>&quot;Reno&quot;</td><td>&quot;Hotels were so…</td></tr><tr><td>2023-04-06 00:00:00</td><td>false</td><td>1001</td><td>&quot;Group Lunch&quot;</td><td>642</td><td>&quot;Seattle&quot;</td><td>&quot;Hotels were so…</td></tr><tr><td>2022-01-26 00:00:00</td><td>true</td><td>1001</td><td>&quot;Meal&quot;</td><td>586</td><td>&quot;Las Vegas&quot;</td><td>&quot;Hotels were so…</td></tr><tr><td>2022-07-11 00:00:00</td><td>false</td><td>1001</td><td>&quot;Lodging&quot;</td><td>721</td><td>&quot;Reno&quot;</td><td>&quot;Hotels were so…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌──────────────┬─────────┬─────────────┬──────────────┬────────┬───────────┬───────────────────────┐\n",
       "│ AS_OF_DATE   ┆ WEEKDAY ┆ EMPLOYEE_ID ┆ EXPENSE_TYPE ┆ AMOUNT ┆ LOCATION  ┆ JUSTIFICATION         │\n",
       "│ ---          ┆ ---     ┆ ---         ┆ ---          ┆ ---    ┆ ---       ┆ ---                   │\n",
       "│ datetime[μs] ┆ bool    ┆ i64         ┆ str          ┆ i64    ┆ str       ┆ str                   │\n",
       "╞══════════════╪═════════╪═════════════╪══════════════╪════════╪═══════════╪═══════════════════════╡\n",
       "│ 2023-01-23   ┆ false   ┆ 1000        ┆ Lodging      ┆ 955    ┆ New York  ┆ Hotels were sold out  │\n",
       "│ 00:00:00     ┆         ┆             ┆              ┆        ┆           ┆ due to conc…          │\n",
       "│ 2022-10-03   ┆ true    ┆ 1001        ┆ Group Lunch  ┆ 714    ┆ Reno      ┆ Hotels were sold out  │\n",
       "│ 00:00:00     ┆         ┆             ┆              ┆        ┆           ┆ due to conc…          │\n",
       "│ 2023-04-06   ┆ false   ┆ 1001        ┆ Group Lunch  ┆ 642    ┆ Seattle   ┆ Hotels were sold out  │\n",
       "│ 00:00:00     ┆         ┆             ┆              ┆        ┆           ┆ due to conc…          │\n",
       "│ 2022-01-26   ┆ true    ┆ 1001        ┆ Meal         ┆ 586    ┆ Las Vegas ┆ Hotels were sold out  │\n",
       "│ 00:00:00     ┆         ┆             ┆              ┆        ┆           ┆ due to conc…          │\n",
       "│ 2022-07-11   ┆ false   ┆ 1001        ┆ Lodging      ┆ 721    ┆ Reno      ┆ Hotels were sold out  │\n",
       "│ 00:00:00     ┆         ┆             ┆              ┆        ┆           ┆ due to conc…          │\n",
       "└──────────────┴─────────┴─────────────┴──────────────┴────────┴───────────┴───────────────────────┘"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfExpCard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>AMOUNT</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>548.345725</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌────────────┐\n",
       "│ AMOUNT     │\n",
       "│ ---        │\n",
       "│ f64        │\n",
       "╞════════════╡\n",
       "│ 548.345725 │\n",
       "└────────────┘"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## collect standard stats from all dataset\n",
    "\n",
    "# dfExpCard.describe()\n",
    "\n",
    "## average, min, max and total for amount per EXPENSE TYPE by LOCATION\n",
    "dfExpCardStats = dfExpCard.filter((pl.col(\"LOCATION\") == \"San Francisco\") & (pl.col(\"EXPENSE_TYPE\") == \"Lodging\")).select(pl.col(\"AMOUNT\")).mean()\n",
    "# describe().select(pl.col(\"describe\",\"AMOUNT\"))\n",
    "# dfExpCardStats.head()\n",
    "dfExpCardStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build prompts\n",
    "## TEST DATA Prompts ##\n",
    "# respond in one word, is there an anomaly in this data.\n",
    "# find anomalies in this data. \n",
    "\n",
    "# Record 1\n",
    "# Average Lodging in San Francisco on a week day costs $999.\n",
    "# I paid $400 for one night. Assuming 20% tolerance is fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "respond in one word, is there an anomaly in this data.Average Lodging in San Francisco on a week day costs  548.3457249070632. I paid {350} for one night. Assuming {20}% tolerance is fair.\n",
      "Employee ID 1001 has discrepancies in 2023-07-19 00:00:00 expense report.\n",
      "respond in one word, is there an anomaly in this data.Average Lodging in San Francisco on a week day costs  548.3457249070632. I paid {532} for one night. Assuming {20}% tolerance is fair.\n",
      "Employee ID 1002 has discrepancies in 2023-07-19 00:00:00 expense report.\n"
     ]
    }
   ],
   "source": [
    "# build dynamic prompt per day per employee\n",
    "expCardDate = datetime(2023, 7, 19)\n",
    "tolerance = 20\n",
    "\n",
    "for i in range(1001,1003,1):\n",
    "    employeeExp = dfExpCard.filter((pl.col(\"EMPLOYEE_ID\") == i) \n",
    "                                #    & (pl.col(\"AS_OF_DATE\") == expCardDate)\n",
    "                                #    & (pl.col(\"LOCATION\") == \"San Francisco\")\n",
    "                                #  & (pl.col(\"EXPENSE_TYPE\") == \"Lodging\")\n",
    "                             )\n",
    "\n",
    "    prompt = \"respond in one word, is there an anomaly in this data.\"\n",
    "    prompt += \"Average Lodging in San Francisco on a week day costs  \" + str(dfExpCardStats.item(0,0)) \n",
    "    prompt += \". I paid \" + str({employeeExp.item(0,4)}) + \" for one night. Assuming \"\n",
    "    prompt += str({tolerance}) +\"% tolerance is fair.\"\n",
    "    print(prompt)\n",
    "    # call ChatGPT | Llama API\n",
    "    if callLlama(prompt) == \"Yes\":\n",
    "        print(f\"Employee ID {i} has discrepancies in {expCardDate} expense report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employeeExp = dfExpCard.filter((pl.col(\"EMPLOYEE_ID\") == 1001)\n",
    "                           & (pl.col(\"LOCATION\") == \"San Francisco\"))\n",
    "\n",
    "employeeExp.item(0,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The use case discussed above exemplify sophisticated business processes and there is certainly lot more which is not covered. \n",
    "\n",
    "This use case merely scratch the surface of what can be achieved with these advanced tools. \n",
    "\n",
    "You may argue that the same results can be attained using simple algebraic mathematics with these datasets, and I fully support and agree with this observation.\n",
    "\n",
    "In essence, the entire field, encompassing Data Science, Python, Llama, and ChatGPT, revolves around uncovering statistical associations within data.\n",
    "\n",
    "However, it is crucial to recognize that the deployment of Llama or ChatGPT-like models does not surpass the importance of traditional statistics,\n",
    "instead, they should be employed to streamline specific tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
