{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama | ChatGPT : Revolutionizing Supply Chain tasks which no human assistant dare to tackle\n",
    "---\n",
    "\n",
    "    Author: Amit Shukla\n",
    "\n",
    "[https://github.com/AmitXShukla](https://github.com/AmitXShukla)\n",
    "\n",
    "[https://twitter.com/ashuklax](https://github.com/AShuklaX)\n",
    "\n",
    "[https://youtube.com/@Amit.Shukla](https://youtube.com/@Amit.Shukla)\n",
    "\n",
    "\n",
    "Meta has recently released Llama 2, a large language model trained with up to 70B parameters, positioning it as the fastest and most advanced solution available. This model is expected to outperform other tools in terms of both speed and accuracy.\n",
    "\n",
    "In this blog post, I will demonstrate some automation use cases I have been working on. \n",
    "\n",
    "It's important to note that these use cases/models will work best when trained on \"in-house\" data. However, training such models is a rigorous task that requires significant computing hours and resources.\n",
    "\n",
    "To make things more accessible and easier to utilize in production, using \"off the shelf\", language models like ChatGPT and Llama 2 is a viable solution.\n",
    "\n",
    "Below, I present some examples of use cases I've been working on. \n",
    "\n",
    "*While these examples are not meant for production*, they still showcase the powerful capabilities of the language models.\n",
    "\n",
    "`Upon completing this blog, you will acquire the skills to build Llama 2 and ChatGPT APIs and harness the capabilities of large language models for practical data analytics tasks.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "---\n",
    "\n",
    "- Introduction\n",
    "- [Llama 2 Installation Windows/Linux](https://github.com/AmitXShukla/RPA/blob/main/notebooks/llama2-UseCases.ipynb)\n",
    "- [Efficient Time and Expense Monitoring with Llama 2](https://github.com/AmitXShukla/RPA/blob/main/notebooks/llama2-Efficient%20Time%20and%20Expense%20Monitoring%20with%20Llama%202.ipynb)\n",
    "- [Using Llama 2 as OCR Vision AI](https://github.com/AmitXShukla/RPA/blob/main/notebooks/llama2-Using%20Llama%202%20as%20OCR%20Vision%20AI.ipynb)\n",
    "- [Llama 2 as Supply Chain Assistant](https://github.com/AmitXShukla/RPA/blob/main/notebooks/llama2-as%20Supply%20Chain%20assistant.ipynb)\n",
    "    - Streamlining 3-Way Receipt Match and Duplicate Voucher Invoices with Llama 2\n",
    "    - Enhancing Fraud Detection: Utilizing Llama 2 as an Advanced Alert System for Monitoring Transactions\n",
    "    - Maximizing Tax Savings, Ensuring Compliance, and Streamlining Audits with Llama 2\n",
    "-  `**WIP**`: Tax Analytics | Spend Classification | Contracts management\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About me\n",
    "I'm Amit Shukla, and I specialize in training neural networks for Finance Supply Chain analysis, enabling them to identify data patterns and make accurate predictions.\n",
    "\n",
    "During the challenges posed by the COVID-19 pandemic, I successfully trained GL and Supply Chain neural networks to anticipate supply chain shortages. The valuable insights gained from this effort have significantly influenced the content of this tutorial series.\n",
    "\t\n",
    "#### Objective:\n",
    "By delving into this powerful tool, we will master the fundamental techniques of utilizing large language models to predict hazards. \n",
    "This knowledge is crucial in preparing finance and supply chain data for advanced analytics, visualization, and predictive modeling using neural networks and machine learning.\n",
    "\t\n",
    "#### Subject\n",
    "It is crucial to emphasize that this specific series will focus exclusively on presenting `production-like examples that demonstrate certain use cases`. It is not intended for production applications. \n",
    "\n",
    "Nevertheless, these examples illustrate highly potent techniques that have practical applications in real-world Data Analytics.\n",
    "\t\n",
    "#### Following\n",
    "In future installments, we will explore Data Analytics and delve into the realm of Data Analytics and machine learning for predictive analytics.\n",
    "\n",
    "Thank you for joining me, and I'm excited to embark on this educational journey together.\n",
    "\t\n",
    "Let's get started.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous video, I demonstrated the process of activating the Open ChatGPT and Llama environments. \n",
    "\n",
    "In this section, I will guide you through the steps to install Llama 2 on a Windows operating system. \n",
    "\n",
    "While the installation process is quite similar to that on Linux, there are a few minor changes that need to be considered. \n",
    "\n",
    "Let's get started!\n",
    "\n",
    "- Step 1: `download miniconda windows installer` [https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)\n",
    "- Step 2: create a new conda environment (say llamaConda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before you setup your machine for llama 2, check if you have cuda on your machine\n",
    "\n",
    "import torch\n",
    "torch.cuda.current_device()\n",
    "# if you don't have cuda and torch on your machine, please move to next step and download cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pytorch cuda\n",
    "# https://pytorch.org/get-started/locally/\n",
    "# uncomment and run this command in Terminal to monitor download progress and debug any error\n",
    "\n",
    "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run these command again and make sure you have cuda available on your machine\n",
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.is_available(),torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this case if you see CUDA out of memory error\n",
    "# also, try to reduce your << --max_batch_size 1 >>, max_split_size_mb:512 and work with \"lowest memory size\" model\n",
    "# !torchrun --nproc_per_node 1 example_text_completion.py --ckpt_dir llama-2-7b --tokenizer_path tokenizer.model --max_seq_len 512 --max_batch_size 1\n",
    "# clear cache\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:24\"\n",
    "\n",
    "# import gc\n",
    "# del variables\n",
    "# gc.collect()\n",
    "\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "signup and receive model download link from meta.\n",
    "\n",
    "[Mete AI website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)\n",
    ">>>\n",
    "    do not use the 'Copy link address' option when you right click the URL. If the copied URL text starts with: https://download.llamameta.net, you copied it correctly. If the copied URL text starts with: https://l.facebook.com, you copied it the wrong way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: uncomment and run this command on your machine\n",
    "# make sure, you have a Git installed on your machine if not\n",
    "# for linux run \n",
    "# sudo apt install git-all\n",
    "\n",
    "# for windows, download git from this link\n",
    "# https://git-scm.com/download/win\n",
    "\n",
    "####### clone Meta llama repo ##########\n",
    "git clone https://github.com/facebookresearch/llama.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browse to root of your llama repo\n",
    "\n",
    "## LINUX\n",
    "# cd llama\n",
    "# chmod +x # ./download.sh\n",
    "# ./download.sh\n",
    "\n",
    "## WINDOWS\n",
    "# bash ./download.sh\n",
    "# if this commands error out, download wget.exe from below link and copy wget.ex to C:\\amit.la\\llama\n",
    "# https://eternallybored.org/misc/wget/\n",
    "# make sure, you include << C:\\amit.la\\llama >> to windows environment path so that windows can find it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure, latest conda env is selected as kernel\n",
    "# before activating and installing dependencies\n",
    "\n",
    "!pip install -e .\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for windows\n",
    "# change line #62 on llama/generate.py\n",
    "# from \n",
    "# << torch.distributed.init_process_group(\"gloo|nccl\") >>\n",
    "# to\n",
    "# << torch.distributed.init_process_group(\"gloo|nccl\") >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure, latest conda env (llamaConda) is selected as kernel\n",
    "# before activating and installing dependencies\n",
    "\n",
    "# !pip install -e .\n",
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./example_text_completion.py\n",
    "# ./example_chat_completion.py\n",
    "\n",
    "# change prompts | dialogue \n",
    "#   prompts = [\n",
    "#         # For these prompts, the expected answer is the natural continuation of the prompt\n",
    "#         \"meaning of life is\",\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you are ready to use llama\n",
    "# !torchrun --nproc_per_node 1 example_text_completion.py --ckpt_dir llama-2-7b --tokenizer_path tokenizer.model --max_seq_len 512 --max_batch_size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addressing Llama | Cuda errors\n",
    "\n",
    "---\n",
    "\n",
    "Here is another solution proposed by one of users who was able to use Llama on CPU machines.\n",
    "\n",
    "** `Please see, If you successfully install this using this approach, please open an Issue at this GitHub repository so that I can update notes.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install https://github.com/krychu/llama instead of https://github.com/facebookresearch/llama\n",
    "\n",
    "# execute download.sh in a new terminal, provide META AI URL and download 7B model and model weights\n",
    "#   run the download.sh script in a terminal, passing the URL provided when prompted to start the download\n",
    "# create a new env\n",
    "\n",
    "# python3 -m venv env\n",
    "# source env/bin/activate\n",
    "\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu #pour la version cpu\n",
    "# python3 -m pip install -e .\n",
    "\n",
    "\n",
    "# torchrun --nproc_per_node 1 example_text_completion.py --ckpt_dir llama-2-7b/ --tokenizer_path tokenizer.model --max_seq_len 128 --max_batch_size 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supply Chain business process\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Flow\n",
    "---\n",
    "\n",
    "The supply chain process, often referred to as the B2P (Buy-to-Pay) or P2P (Procure-to-Pay) process, involves several steps to ensure the efficient procurement and delivery of goods. Let's break down the process step by step:\n",
    "\n",
    "- Inventory Check:\n",
    "    The supply chain process begins with an inventory check. This step involves assessing the current stock levels of goods in the system. It helps to determine which items are running low and need replenishment. This check can be done through various means, such as using software that tracks inventory levels in real-time.\n",
    "\n",
    "- Replenishment Order:\n",
    "    After the inventory check, if the system identifies that certain goods are running low or below the specified threshold, it automatically generates a replenishment order. This order initiates the procurement process and serves as a request for more goods to be obtained from external suppliers.\n",
    "\n",
    "- Purchase Order Creation:\n",
    "    Once the replenishment order is generated, the procurement team or relevant personnel create purchase orders. These purchase orders contain specific details about the requested goods, such as the quantity, item description, agreed-upon price, delivery date, and any other relevant terms and conditions.\n",
    "\n",
    "- Sending Purchase Orders to Vendors:\n",
    "    After the purchase orders are created, they are sent to the approved vendors or suppliers who provide the required goods. The vendors review the purchase orders and acknowledge their acceptance, confirming their commitment to fulfill the order.\n",
    "\n",
    "- Goods Shipment:\n",
    "    Upon receiving the accepted purchase orders, the vendors prepare the goods for shipment. They ensure that the correct quantity and quality of goods are packed and ready for delivery. The vendors then send the goods to the customer's designated delivery location.\n",
    "\n",
    "- Receipt Generation:\n",
    "    Once the goods are successfully delivered to the customer, the receiving team checks and verifies the received items against the details mentioned in the purchase order. If everything matches and there are no discrepancies, they generate a receipt confirming the receipt and acceptance of the goods.\n",
    "\n",
    "- Invoicing and Payment:\n",
    "    After the receipt is generated, the vendor sends an invoice to the customer for payment. The invoice contains details of the goods provided, their quantity, prices, any applicable taxes, and the total amount due. The customer reviews the invoice and makes the necessary payment to the vendor within the agreed-upon payment terms.\n",
    "\n",
    "- Payment Settlement:\n",
    "    Finally, the customer processes the payment, settling the outstanding invoice amount with the vendor. This completes the procurement process for the specific order.\n",
    "\n",
    "The supply chain process is a continuous cycle, and the steps repeat as new demands arise, and inventory needs to be replenished. Efficiently managing the supply chain ensures that goods are available when needed, minimizing delays and disruptions in the supply of products or services.\n",
    "\n",
    "![Data Flow](../SampleData/ER_Flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Process Flow\n",
    "---\n",
    "\n",
    "The vendor payment process, as described in the flow, involves several checks and steps to ensure accuracy, efficiency, and compliance. Let's break down the process:\n",
    "\n",
    "- Receipt or Invoice Document:\n",
    "    The process begins when the supply chain clerk receives either a receipt or an invoice document from the vendor. This document serves as a formal request for payment for the goods or services provided.\n",
    "\n",
    "- Three-Way Match:\n",
    "    The first major step in the vendor payment process is the \"three-way match.\" This involves comparing three key documents: the invoice, the purchase order, and the receipt (or delivery confirmation). The supply chain clerk checks the following:\n",
    "\n",
    "    a. Quantity and Amount: The quantity of items and the total amount charged on the invoice are compared to the quantities specified in the purchase order and the actual receipt. It ensures that the vendor is billing correctly for the goods actually received.\n",
    "\n",
    "    b. Timing: The timing of when the order was placed, shipped, and received is verified to ensure that the delivery was within the expected time frame allowed from order to receipt. Any discrepancies may require investigation or follow-up.\n",
    "\n",
    "- Discount Opportunities:\n",
    "    The supply chain clerk looks for potential discount opportunities offered by the vendor for early payment. Early payment discounts can lead to cost savings, and the clerk ensures that eligible discounts are taken advantage of while making payments on time to avoid penalties.\n",
    "\n",
    "- Contractual Agreement Compliance:\n",
    "    The assistant also checks if the expenses fall under any existing contractual agreements with the vendor. These agreements may include negotiated prices, discounts, or specific terms and conditions that can be leveraged to procure goods or services at the most suitable prices.\n",
    "\n",
    "- Avoiding Duplicate Invoices:\n",
    "    With a large number of orders processed in a day, the possibility of vendors accidentally sending duplicate invoices is common. The supply chain clerk carefully matches and cross-references all received invoices to identify and eliminate any duplicated or erroneous transactions.\n",
    "\n",
    "- Eligibility for Payment:\n",
    "    Once all the necessary checks are performed, and the documents pass the three-way match, the invoices are considered eligible for payment.\n",
    "\n",
    "- Payment Processing:\n",
    "    Based on the eligibility for payment, the supply chain clerk initiates the payment process. This may involve generating payment files, authorizing transactions, and coordinating with the finance department to ensure timely and accurate disbursement of funds to the vendor.\n",
    "\n",
    "By following this comprehensive vendor payment process, the organization can maintain strong vendor relationships, optimize costs, prevent errors, and ensure compliance with contractual agreements and payment terms. It also contributes to the overall efficiency and effectiveness of the supply chain management process.\n",
    "\n",
    "![Business Process](../SampleData/Process_Flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supply chain Buy to Pay Processes Automation\n",
    "---\n",
    "\n",
    "In the upcoming sections, we'll utilize available data to create prompts for LLMs (Large Language Models) to make decisions based on statistical information. \n",
    "\n",
    "However, it's essential to note that LLMs are not universally beneficial and may not be suitable for every scenario. \n",
    "\n",
    "For instance, when dealing with large systems containing millions of documents, using LLMs to compare invoices one by one can be computationally intensive and inefficient. In such cases, alternative data science techniques offer better results and higher efficiency for tasks like identifying duplicate invoices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supply Chain 3 way Match process automation\n",
    "\n",
    "- Step 1: Load Datasets\n",
    "- Step 2: Collect statistics (describe generic behavior)\n",
    "- Step 3: building prompt\n",
    "- Step 4: Checking one Invoice\n",
    "- Step 5: run invoice prompt through LLM (large language model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Faker\n",
    "# !pip install polars\n",
    "# !pip install nltk\n",
    "# !pip install sklearn\n",
    "# !pip install torch\n",
    "# py -m pip install pytesseract : open source\n",
    "# py -m pip install PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load Datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>CUSTOMER_ID</th><th>NAME</th><th>PH</th><th>ADDRESS</th><th>EMAIL_ID</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>9076</td><td>&quot;Melanie Kenned…</td><td>&quot;493-860-2796&quot;</td><td>&quot;9057 Jefferson…</td><td>&quot;elopez@example…</td></tr><tr><td>2891</td><td>&quot;Jacqueline Osb…</td><td>&quot;(322)410-8459x…</td><td>&quot;92734 Ramirez …</td><td>&quot;horncarol@exam…</td></tr><tr><td>4575</td><td>&quot;Anthony Myers&quot;</td><td>&quot;5814746103&quot;</td><td>&quot;4456 Evans Fie…</td><td>&quot;aburns@example…</td></tr><tr><td>5047</td><td>&quot;Andrea Sampson…</td><td>&quot;425.769.9987&quot;</td><td>&quot;55081 Barker P…</td><td>&quot;cschultz@examp…</td></tr><tr><td>6918</td><td>&quot;Angela Wise&quot;</td><td>&quot;9645319781&quot;</td><td>&quot;40069 Jim Ramp…</td><td>&quot;xlyons@example…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────────┬───────────────────┬───────────────────┬──────────────────────┬─────────────────────┐\n",
       "│ CUSTOMER_ID ┆ NAME              ┆ PH                ┆ ADDRESS              ┆ EMAIL_ID            │\n",
       "│ ---         ┆ ---               ┆ ---               ┆ ---                  ┆ ---                 │\n",
       "│ i64         ┆ str               ┆ str               ┆ str                  ┆ str                 │\n",
       "╞═════════════╪═══════════════════╪═══════════════════╪══════════════════════╪═════════════════════╡\n",
       "│ 9076        ┆ Melanie Kennedy   ┆ 493-860-2796      ┆ 9057 Jefferson Knoll ┆ elopez@example.org  │\n",
       "│             ┆                   ┆                   ┆ Wilsontown,…         ┆                     │\n",
       "│ 2891        ┆ Jacqueline Osborn ┆ (322)410-8459x556 ┆ 92734 Ramirez Corner ┆ horncarol@example.c │\n",
       "│             ┆                   ┆                   ┆ Cruztown, M…         ┆ om                  │\n",
       "│ 4575        ┆ Anthony Myers     ┆ 5814746103        ┆ 4456 Evans Fields    ┆ aburns@example.net  │\n",
       "│             ┆                   ┆                   ┆ Apt. 114             ┆                     │\n",
       "│             ┆                   ┆                   ┆ North…               ┆                     │\n",
       "│ 5047        ┆ Andrea Sampson    ┆ 425.769.9987      ┆ 55081 Barker Prairie ┆ cschultz@example.ne │\n",
       "│             ┆                   ┆                   ┆ East Daniel…         ┆ t                   │\n",
       "│ 6918        ┆ Angela Wise       ┆ 9645319781        ┆ 40069 Jim Ramp       ┆ xlyons@example.com  │\n",
       "│             ┆                   ┆                   ┆ Lake Michellefort…   ┆                     │\n",
       "└─────────────┴───────────────────┴───────────────────┴──────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## Step 1 #####\n",
    "# Load DataSets\n",
    "# Customer, Vendor, Product, Product-Category\n",
    "\n",
    "# load libraries\n",
    "from datetime import datetime, timedelta\n",
    "import polars as pl\n",
    "from faker import Faker\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# create list of values\n",
    "fake = Faker()\n",
    "ID = list(set(fake.unique.random_int() for i in range(1000)))\n",
    "PH = []\n",
    "NAME = []\n",
    "EMAIL = []\n",
    "ADDRESS = []\n",
    "COMPANY = []\n",
    "PRODUCT = []\n",
    "PRODUCT_CATEGORY = []\n",
    "\n",
    "for i in range(1000):\n",
    "    PH.append(fake.unique.phone_number())\n",
    "    NAME.append(fake.unique.name())\n",
    "    EMAIL.append(fake.unique.email())\n",
    "    ADDRESS.append(fake.unique.address())\n",
    "    COMPANY.append(fake.unique.company())\n",
    "    PRODUCT.append(fake.bothify(text='Product Number: ????-########'))\n",
    "    PRODUCT_CATEGORY.append(fake.isbn10())\n",
    "\n",
    "#####################\n",
    "# CUSTOMER DataFrame\n",
    "#####################\n",
    "\n",
    "dfCustomer = pl.DataFrame({\n",
    "    \"CUSTOMER_ID\": ID,\n",
    "    \"NAME\" : NAME,\n",
    "    \"PH\" : PH,\n",
    "    \"ADDRESS\" : ADDRESS,\n",
    "    \"EMAIL_ID\" : EMAIL\n",
    "})\n",
    "\n",
    "dfCustomer.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>VENDOR_ID</th><th>NAME</th><th>PH</th><th>ADDRESS</th><th>EMAIL_ID</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>8637</td><td>&quot;Thomas-Smith&quot;</td><td>&quot;359-804-9258&quot;</td><td>&quot;23506 Smith Pa…</td><td>&quot;zlee@example.o…</td></tr><tr><td>7789</td><td>&quot;Jones-Jones&quot;</td><td>&quot;+1-999-627-177…</td><td>&quot;626 Brandy Exp…</td><td>&quot;qrodriguez@exa…</td></tr><tr><td>8406</td><td>&quot;Cisneros-Lee&quot;</td><td>&quot;913.371.7526&quot;</td><td>&quot;33314 Martha M…</td><td>&quot;yvonnelawson@e…</td></tr><tr><td>4546</td><td>&quot;Garcia-Martin&quot;</td><td>&quot;+1-847-287-829…</td><td>&quot;65968 Goodwin …</td><td>&quot;gregoryaguirre…</td></tr><tr><td>4719</td><td>&quot;Silva, Rios an…</td><td>&quot;285.461.1459x1…</td><td>&quot;349 Crystal La…</td><td>&quot;amy45@example.…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌───────────┬─────────────────┬──────────────────────┬──────────────────────┬──────────────────────┐\n",
       "│ VENDOR_ID ┆ NAME            ┆ PH                   ┆ ADDRESS              ┆ EMAIL_ID             │\n",
       "│ ---       ┆ ---             ┆ ---                  ┆ ---                  ┆ ---                  │\n",
       "│ i64       ┆ str             ┆ str                  ┆ str                  ┆ str                  │\n",
       "╞═══════════╪═════════════════╪══════════════════════╪══════════════════════╪══════════════════════╡\n",
       "│ 8637      ┆ Thomas-Smith    ┆ 359-804-9258         ┆ 23506 Smith Path     ┆ zlee@example.org     │\n",
       "│           ┆                 ┆                      ┆ East Tiffanytow…     ┆                      │\n",
       "│ 7789      ┆ Jones-Jones     ┆ +1-999-627-1771x5094 ┆ 626 Brandy           ┆ qrodriguez@example.c │\n",
       "│           ┆                 ┆                      ┆ Expressway Apt. 322  ┆ om                   │\n",
       "│           ┆                 ┆                      ┆ A…                   ┆                      │\n",
       "│ 8406      ┆ Cisneros-Lee    ┆ 913.371.7526         ┆ 33314 Martha         ┆ yvonnelawson@example │\n",
       "│           ┆                 ┆                      ┆ Mountain Apt. 885    ┆ .com                 │\n",
       "│           ┆                 ┆                      ┆ B…                   ┆                      │\n",
       "│ 4546      ┆ Garcia-Martin   ┆ +1-847-287-8292x5193 ┆ 65968 Goodwin        ┆ gregoryaguirre@examp │\n",
       "│           ┆                 ┆                      ┆ Station Apt. 441     ┆ le.net               │\n",
       "│           ┆                 ┆                      ┆ W…                   ┆                      │\n",
       "│ 4719      ┆ Silva, Rios and ┆ 285.461.1459x184     ┆ 349 Crystal Land     ┆ amy45@example.com    │\n",
       "│           ┆ Scott           ┆                      ┆ Port Brettborou…     ┆                      │\n",
       "└───────────┴─────────────────┴──────────────────────┴──────────────────────┴──────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfVendor = pl.DataFrame({\n",
    "    \"VENDOR_ID\": ID,\n",
    "    \"NAME\" : COMPANY,\n",
    "    \"PH\" : PH,\n",
    "    \"ADDRESS\" : ADDRESS,\n",
    "    \"EMAIL_ID\" : EMAIL\n",
    "})\n",
    "\n",
    "dfVendor.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PRODUCT_ID</th><th>PRODUCT</th><th>PRODUCT_CATEGORY</th><th>MANUFACTURER</th><th>PRICE</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>8475</td><td>&quot;Product Number…</td><td>&quot;0-7658-3384-0&quot;</td><td>&quot;Grant-Reyes&quot;</td><td>7974</td></tr><tr><td>2120</td><td>&quot;Product Number…</td><td>&quot;1-69888-169-X&quot;</td><td>&quot;Williams, Jose…</td><td>6712</td></tr><tr><td>3288</td><td>&quot;Product Number…</td><td>&quot;0-8155-7334-0&quot;</td><td>&quot;Myers Inc&quot;</td><td>5775</td></tr><tr><td>4101</td><td>&quot;Product Number…</td><td>&quot;0-262-40429-X&quot;</td><td>&quot;Armstrong, Sut…</td><td>963</td></tr><tr><td>3969</td><td>&quot;Product Number…</td><td>&quot;0-7910-9578-9&quot;</td><td>&quot;Rice Inc&quot;</td><td>4609</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────────┬─────────────────┬──────────────────┬────────────────────────────┬───────┐\n",
       "│ PRODUCT_ID ┆ PRODUCT         ┆ PRODUCT_CATEGORY ┆ MANUFACTURER               ┆ PRICE │\n",
       "│ ---        ┆ ---             ┆ ---              ┆ ---                        ┆ ---   │\n",
       "│ i64        ┆ str             ┆ str              ┆ str                        ┆ i64   │\n",
       "╞════════════╪═════════════════╪══════════════════╪════════════════════════════╪═══════╡\n",
       "│ 8475       ┆ Product Number: ┆ 0-7658-3384-0    ┆ Grant-Reyes                ┆ 7974  │\n",
       "│            ┆ kCze-67041789   ┆                  ┆                            ┆       │\n",
       "│ 2120       ┆ Product Number: ┆ 1-69888-169-X    ┆ Williams, Joseph and King  ┆ 6712  │\n",
       "│            ┆ zcRc-73487327   ┆                  ┆                            ┆       │\n",
       "│ 3288       ┆ Product Number: ┆ 0-8155-7334-0    ┆ Myers Inc                  ┆ 5775  │\n",
       "│            ┆ AOOB-41891795   ┆                  ┆                            ┆       │\n",
       "│ 4101       ┆ Product Number: ┆ 0-262-40429-X    ┆ Armstrong, Sutton and Kemp ┆ 963   │\n",
       "│            ┆ COnL-03052713   ┆                  ┆                            ┆       │\n",
       "│ 3969       ┆ Product Number: ┆ 0-7910-9578-9    ┆ Rice Inc                   ┆ 4609  │\n",
       "│            ┆ qAVp-41453070   ┆                  ┆                            ┆       │\n",
       "└────────────┴─────────────────┴──────────────────┴────────────────────────────┴───────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfProduct = pl.DataFrame({\n",
    "    \"PRODUCT_ID\": ID,\n",
    "    \"PRODUCT\" : PRODUCT,\n",
    "    \"PRODUCT_CATEGORY\" : PRODUCT_CATEGORY,\n",
    "    \"MANUFACTURER\" : COMPANY,\n",
    "    \"PRICE\" : random.sample(range(10000), 1000)\n",
    "})\n",
    "\n",
    "dfProduct.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PO_ID</th><th>AS_OF_DATE</th><th>CUSTOMER_ID</th><th>VENDOR_ID</th><th>PRODUCT_ID</th><th>QTY</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>49786</td><td>2023-07-17 00:00:00</td><td>6990</td><td>1381</td><td>3594</td><td>19</td></tr><tr><td>13022</td><td>2022-11-04 00:00:00</td><td>4617</td><td>880</td><td>7304</td><td>31</td></tr><tr><td>18669</td><td>2022-02-02 00:00:00</td><td>3787</td><td>5509</td><td>7590</td><td>30</td></tr><tr><td>72139</td><td>2022-02-19 00:00:00</td><td>2639</td><td>698</td><td>8357</td><td>13</td></tr><tr><td>74971</td><td>2022-08-15 00:00:00</td><td>6367</td><td>4810</td><td>656</td><td>35</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌───────┬─────────────────────┬─────────────┬───────────┬────────────┬─────┐\n",
       "│ PO_ID ┆ AS_OF_DATE          ┆ CUSTOMER_ID ┆ VENDOR_ID ┆ PRODUCT_ID ┆ QTY │\n",
       "│ ---   ┆ ---                 ┆ ---         ┆ ---       ┆ ---        ┆ --- │\n",
       "│ i64   ┆ datetime[μs]        ┆ i64         ┆ i64       ┆ i64        ┆ i64 │\n",
       "╞═══════╪═════════════════════╪═════════════╪═══════════╪════════════╪═════╡\n",
       "│ 49786 ┆ 2023-07-17 00:00:00 ┆ 6990        ┆ 1381      ┆ 3594       ┆ 19  │\n",
       "│ 13022 ┆ 2022-11-04 00:00:00 ┆ 4617        ┆ 880       ┆ 7304       ┆ 31  │\n",
       "│ 18669 ┆ 2022-02-02 00:00:00 ┆ 3787        ┆ 5509      ┆ 7590       ┆ 30  │\n",
       "│ 72139 ┆ 2022-02-19 00:00:00 ┆ 2639        ┆ 698       ┆ 8357       ┆ 13  │\n",
       "│ 74971 ┆ 2022-08-15 00:00:00 ┆ 6367        ┆ 4810      ┆ 656        ┆ 35  │\n",
       "└───────┴─────────────────────┴─────────────┴───────────┴────────────┴─────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load DataSets\n",
    "# Purchase Order\n",
    "sampleSize = 100_000\n",
    "dfPurOrder = pl.DataFrame({\n",
    "    \"PO_ID\": list(range(1,sampleSize+1)),\n",
    "    'AS_OF_DATE': random.choices(pl.date_range(datetime(2022, 1, 1), datetime(2023, 7, 20), timedelta(days=1), time_unit=\"ms\"), k=sampleSize),\n",
    "    \"CUSTOMER_ID\": random.choices(dfCustomer[\"CUSTOMER_ID\"], k=sampleSize),\n",
    "    \"VENDOR_ID\": random.choices(dfVendor[\"VENDOR_ID\"], k=sampleSize),\n",
    "    \"PRODUCT_ID\" : random.choices(dfProduct[\"PRODUCT_ID\"], k=sampleSize),\n",
    "    \"QTY\" : list(np.random.randint(1,50, sampleSize))\n",
    "})\n",
    "\n",
    "dfPurOrder.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PO_ID</th><th>AS_OF_DATE</th><th>CUSTOMER_ID</th><th>VENDOR_ID</th><th>PRODUCT_ID</th><th>QTY</th><th>PRODUCT</th><th>PRODUCT_CATEGORY</th><th>MANUFACTURER</th><th>PRICE</th><th>TOTAL</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>96447</td><td>2023-07-06 00:00:00</td><td>3602</td><td>2774</td><td>7848</td><td>5</td><td>&quot;Product Number…</td><td>&quot;0-7397-0577-6&quot;</td><td>&quot;Sandoval-Evans…</td><td>5576</td><td>27880</td></tr><tr><td>20138</td><td>2022-12-12 00:00:00</td><td>3975</td><td>3349</td><td>3849</td><td>35</td><td>&quot;Product Number…</td><td>&quot;0-341-79496-1&quot;</td><td>&quot;Edwards-Hill&quot;</td><td>4976</td><td>174160</td></tr><tr><td>63650</td><td>2022-12-31 00:00:00</td><td>693</td><td>5537</td><td>9850</td><td>42</td><td>&quot;Product Number…</td><td>&quot;1-07-607178-3&quot;</td><td>&quot;Gutierrez Ltd&quot;</td><td>627</td><td>26334</td></tr><tr><td>40985</td><td>2022-01-15 00:00:00</td><td>5312</td><td>2774</td><td>8237</td><td>48</td><td>&quot;Product Number…</td><td>&quot;0-7152-3807-8&quot;</td><td>&quot;Miller, Thomas…</td><td>6365</td><td>305520</td></tr><tr><td>9725</td><td>2022-12-10 00:00:00</td><td>8024</td><td>5847</td><td>9093</td><td>9</td><td>&quot;Product Number…</td><td>&quot;0-9975989-4-8&quot;</td><td>&quot;Holder, Waller…</td><td>8074</td><td>72666</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌───────┬───────────────┬─────────────┬───────────┬───┬────────────┬──────────────┬───────┬────────┐\n",
       "│ PO_ID ┆ AS_OF_DATE    ┆ CUSTOMER_ID ┆ VENDOR_ID ┆ … ┆ PRODUCT_CA ┆ MANUFACTURER ┆ PRICE ┆ TOTAL  │\n",
       "│ ---   ┆ ---           ┆ ---         ┆ ---       ┆   ┆ TEGORY     ┆ ---          ┆ ---   ┆ ---    │\n",
       "│ i64   ┆ datetime[μs]  ┆ i64         ┆ i64       ┆   ┆ ---        ┆ str          ┆ i64   ┆ i64    │\n",
       "│       ┆               ┆             ┆           ┆   ┆ str        ┆              ┆       ┆        │\n",
       "╞═══════╪═══════════════╪═════════════╪═══════════╪═══╪════════════╪══════════════╪═══════╪════════╡\n",
       "│ 96447 ┆ 2023-07-06    ┆ 3602        ┆ 2774      ┆ … ┆ 0-7397-057 ┆ Sandoval-Eva ┆ 5576  ┆ 27880  │\n",
       "│       ┆ 00:00:00      ┆             ┆           ┆   ┆ 7-6        ┆ ns           ┆       ┆        │\n",
       "│ 20138 ┆ 2022-12-12    ┆ 3975        ┆ 3349      ┆ … ┆ 0-341-7949 ┆ Edwards-Hill ┆ 4976  ┆ 174160 │\n",
       "│       ┆ 00:00:00      ┆             ┆           ┆   ┆ 6-1        ┆              ┆       ┆        │\n",
       "│ 63650 ┆ 2022-12-31    ┆ 693         ┆ 5537      ┆ … ┆ 1-07-60717 ┆ Gutierrez    ┆ 627   ┆ 26334  │\n",
       "│       ┆ 00:00:00      ┆             ┆           ┆   ┆ 8-3        ┆ Ltd          ┆       ┆        │\n",
       "│ 40985 ┆ 2022-01-15    ┆ 5312        ┆ 2774      ┆ … ┆ 0-7152-380 ┆ Miller,      ┆ 6365  ┆ 305520 │\n",
       "│       ┆ 00:00:00      ┆             ┆           ┆   ┆ 7-8        ┆ Thomas and   ┆       ┆        │\n",
       "│       ┆               ┆             ┆           ┆   ┆            ┆ Jensen       ┆       ┆        │\n",
       "│ 9725  ┆ 2022-12-10    ┆ 8024        ┆ 5847      ┆ … ┆ 0-9975989- ┆ Holder,      ┆ 8074  ┆ 72666  │\n",
       "│       ┆ 00:00:00      ┆             ┆           ┆   ┆ 4-8        ┆ Waller and   ┆       ┆        │\n",
       "│       ┆               ┆             ┆           ┆   ┆            ┆ Banks        ┆       ┆        │\n",
       "└───────┴───────────────┴─────────────┴───────────┴───┴────────────┴──────────────┴───────┴────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load DataSets\n",
    "# Invoice\n",
    "dfInvoice = dfPurOrder.join(dfProduct, on=\"PRODUCT_ID\", how=\"inner\").with_columns(\n",
    "    (pl.col(\"QTY\")*pl.col(\"PRICE\")).alias(\"TOTAL\")\n",
    ")\n",
    "\n",
    "dfInvoice.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PO_ID</th><th>AS_OF_DATE</th><th>CUSTOMER_ID</th><th>VENDOR_ID</th><th>PRODUCT_ID</th><th>QTY</th><th>PRODUCT</th><th>PRODUCT_CATEGORY</th><th>MANUFACTURER</th><th>PRICE</th><th>TOTAL</th><th>PRODUCT_right</th><th>PRODUCT_CATEGORY_right</th><th>MANUFACTURER_right</th><th>PRICE_right</th><th>RECV_STATUS</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>bool</td></tr></thead><tbody><tr><td>51383</td><td>2023-04-16 00:00:00</td><td>7743</td><td>1962</td><td>4686</td><td>15</td><td>&quot;Product Number…</td><td>&quot;1-07-919635-8&quot;</td><td>&quot;Rodriguez, San…</td><td>8970</td><td>134550</td><td>&quot;Product Number…</td><td>&quot;1-07-919635-8&quot;</td><td>&quot;Rodriguez, San…</td><td>8970</td><td>true</td></tr><tr><td>82514</td><td>2022-09-28 00:00:00</td><td>5681</td><td>6934</td><td>4851</td><td>23</td><td>&quot;Product Number…</td><td>&quot;0-9835399-4-4&quot;</td><td>&quot;Mann Group&quot;</td><td>6884</td><td>158332</td><td>&quot;Product Number…</td><td>&quot;0-9835399-4-4&quot;</td><td>&quot;Mann Group&quot;</td><td>6884</td><td>true</td></tr><tr><td>79397</td><td>2022-10-16 00:00:00</td><td>64</td><td>7425</td><td>8921</td><td>6</td><td>&quot;Product Number…</td><td>&quot;1-140-93201-2&quot;</td><td>&quot;Brewer, Vasque…</td><td>5913</td><td>35478</td><td>&quot;Product Number…</td><td>&quot;1-140-93201-2&quot;</td><td>&quot;Brewer, Vasque…</td><td>5913</td><td>true</td></tr><tr><td>59851</td><td>2023-05-04 00:00:00</td><td>3682</td><td>4979</td><td>5022</td><td>39</td><td>&quot;Product Number…</td><td>&quot;0-12-053640-4&quot;</td><td>&quot;Gregory and So…</td><td>6451</td><td>251589</td><td>&quot;Product Number…</td><td>&quot;0-12-053640-4&quot;</td><td>&quot;Gregory and So…</td><td>6451</td><td>true</td></tr><tr><td>43265</td><td>2023-03-15 00:00:00</td><td>1060</td><td>9850</td><td>9713</td><td>2</td><td>&quot;Product Number…</td><td>&quot;1-104-21292-7&quot;</td><td>&quot;Garcia, Odonne…</td><td>3883</td><td>7766</td><td>&quot;Product Number…</td><td>&quot;1-104-21292-7&quot;</td><td>&quot;Garcia, Odonne…</td><td>3883</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 16)\n",
       "┌───────┬──────────┬───────────┬───────────┬───┬────────────┬────────────┬───────────┬─────────────┐\n",
       "│ PO_ID ┆ AS_OF_DA ┆ CUSTOMER_ ┆ VENDOR_ID ┆ … ┆ PRODUCT_CA ┆ MANUFACTUR ┆ PRICE_rig ┆ RECV_STATUS │\n",
       "│ ---   ┆ TE       ┆ ID        ┆ ---       ┆   ┆ TEGORY_rig ┆ ER_right   ┆ ht        ┆ ---         │\n",
       "│ i64   ┆ ---      ┆ ---       ┆ i64       ┆   ┆ ht         ┆ ---        ┆ ---       ┆ bool        │\n",
       "│       ┆ datetime ┆ i64       ┆           ┆   ┆ ---        ┆ str        ┆ i64       ┆             │\n",
       "│       ┆ [μs]     ┆           ┆           ┆   ┆ str        ┆            ┆           ┆             │\n",
       "╞═══════╪══════════╪═══════════╪═══════════╪═══╪════════════╪════════════╪═══════════╪═════════════╡\n",
       "│ 51383 ┆ 2023-04- ┆ 7743      ┆ 1962      ┆ … ┆ 1-07-91963 ┆ Rodriguez, ┆ 8970      ┆ true        │\n",
       "│       ┆ 16       ┆           ┆           ┆   ┆ 5-8        ┆ Sandoval   ┆           ┆             │\n",
       "│       ┆ 00:00:00 ┆           ┆           ┆   ┆            ┆ and Boyd   ┆           ┆             │\n",
       "│ 82514 ┆ 2022-09- ┆ 5681      ┆ 6934      ┆ … ┆ 0-9835399- ┆ Mann Group ┆ 6884      ┆ true        │\n",
       "│       ┆ 28       ┆           ┆           ┆   ┆ 4-4        ┆            ┆           ┆             │\n",
       "│       ┆ 00:00:00 ┆           ┆           ┆   ┆            ┆            ┆           ┆             │\n",
       "│ 79397 ┆ 2022-10- ┆ 64        ┆ 7425      ┆ … ┆ 1-140-9320 ┆ Brewer,    ┆ 5913      ┆ true        │\n",
       "│       ┆ 16       ┆           ┆           ┆   ┆ 1-2        ┆ Vasquez    ┆           ┆             │\n",
       "│       ┆ 00:00:00 ┆           ┆           ┆   ┆            ┆ and Palmer ┆           ┆             │\n",
       "│ 59851 ┆ 2023-05- ┆ 3682      ┆ 4979      ┆ … ┆ 0-12-05364 ┆ Gregory    ┆ 6451      ┆ true        │\n",
       "│       ┆ 04       ┆           ┆           ┆   ┆ 0-4        ┆ and Sons   ┆           ┆             │\n",
       "│       ┆ 00:00:00 ┆           ┆           ┆   ┆            ┆            ┆           ┆             │\n",
       "│ 43265 ┆ 2023-03- ┆ 1060      ┆ 9850      ┆ … ┆ 1-104-2129 ┆ Garcia,    ┆ 3883      ┆ true        │\n",
       "│       ┆ 15       ┆           ┆           ┆   ┆ 2-7        ┆ Odonnell   ┆           ┆             │\n",
       "│       ┆ 00:00:00 ┆           ┆           ┆   ┆            ┆ and        ┆           ┆             │\n",
       "│       ┆          ┆           ┆           ┆   ┆            ┆ Collins    ┆           ┆             │\n",
       "└───────┴──────────┴───────────┴───────────┴───┴────────────┴────────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load DataSets\n",
    "# Receipt, Payment\n",
    "\n",
    "dfReceipt = dfInvoice.join(dfProduct, on=\"PRODUCT_ID\", how=\"inner\").with_columns(\n",
    "    pl.when(pl.col(\"QTY\") < 42)\n",
    "    .then(pl.lit(True))\n",
    "    .otherwise(pl.lit(False))\n",
    "    .alias(\"RECV_STATUS\")\n",
    ")\n",
    "\n",
    "dfReceipt.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Collect statistics (describe generic behavior)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PRODUCT_ID</th><th>avg_qty_ordered</th><th>avg_price_paid</th><th>PRODUCT</th><th>PRODUCT_CATEGORY</th><th>MANUFACTURER</th><th>PRICE</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>7777</td><td>2698</td><td>13522376</td><td>&quot;Product Number…</td><td>&quot;0-310-79434-X&quot;</td><td>&quot;Powell-Barnes&quot;</td><td>5012</td></tr><tr><td>9778</td><td>2317</td><td>6336995</td><td>&quot;Product Number…</td><td>&quot;0-256-06737-6&quot;</td><td>&quot;Nelson, Nelson…</td><td>2735</td></tr><tr><td>2947</td><td>2255</td><td>15185170</td><td>&quot;Product Number…</td><td>&quot;1-141-75086-4&quot;</td><td>&quot;Roth, Smith an…</td><td>6734</td></tr><tr><td>486</td><td>2752</td><td>21418816</td><td>&quot;Product Number…</td><td>&quot;1-133-38253-3&quot;</td><td>&quot;Mcclure, Corte…</td><td>7783</td></tr><tr><td>7101</td><td>2840</td><td>26275680</td><td>&quot;Product Number…</td><td>&quot;0-497-60622-4&quot;</td><td>&quot;Thornton Inc&quot;</td><td>9252</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌────────────┬───────────────┬───────────────┬───────────────┬──────────────┬──────────────┬───────┐\n",
       "│ PRODUCT_ID ┆ avg_qty_order ┆ avg_price_pai ┆ PRODUCT       ┆ PRODUCT_CATE ┆ MANUFACTURER ┆ PRICE │\n",
       "│ ---        ┆ ed            ┆ d             ┆ ---           ┆ GORY         ┆ ---          ┆ ---   │\n",
       "│ i64        ┆ ---           ┆ ---           ┆ str           ┆ ---          ┆ str          ┆ i64   │\n",
       "│            ┆ i64           ┆ i64           ┆               ┆ str          ┆              ┆       │\n",
       "╞════════════╪═══════════════╪═══════════════╪═══════════════╪══════════════╪══════════════╪═══════╡\n",
       "│ 7777       ┆ 2698          ┆ 13522376      ┆ Product       ┆ 0-310-79434- ┆ Powell-Barne ┆ 5012  │\n",
       "│            ┆               ┆               ┆ Number:       ┆ X            ┆ s            ┆       │\n",
       "│            ┆               ┆               ┆ RBPc-17930074 ┆              ┆              ┆       │\n",
       "│ 9778       ┆ 2317          ┆ 6336995       ┆ Product       ┆ 0-256-06737- ┆ Nelson,      ┆ 2735  │\n",
       "│            ┆               ┆               ┆ Number:       ┆ 6            ┆ Nelson and   ┆       │\n",
       "│            ┆               ┆               ┆ JGQL-77460103 ┆              ┆ Mitchell     ┆       │\n",
       "│ 2947       ┆ 2255          ┆ 15185170      ┆ Product       ┆ 1-141-75086- ┆ Roth, Smith  ┆ 6734  │\n",
       "│            ┆               ┆               ┆ Number:       ┆ 4            ┆ and Smith    ┆       │\n",
       "│            ┆               ┆               ┆ piXv-47004045 ┆              ┆              ┆       │\n",
       "│ 486        ┆ 2752          ┆ 21418816      ┆ Product       ┆ 1-133-38253- ┆ Mcclure,     ┆ 7783  │\n",
       "│            ┆               ┆               ┆ Number:       ┆ 3            ┆ Cortez and   ┆       │\n",
       "│            ┆               ┆               ┆ hwIg-18977694 ┆              ┆ Fox          ┆       │\n",
       "│ 7101       ┆ 2840          ┆ 26275680      ┆ Product       ┆ 0-497-60622- ┆ Thornton Inc ┆ 9252  │\n",
       "│            ┆               ┆               ┆ Number:       ┆ 4            ┆              ┆       │\n",
       "│            ┆               ┆               ┆ cvzO-01938524 ┆              ┆              ┆       │\n",
       "└────────────┴───────────────┴───────────────┴───────────────┴──────────────┴──────────────┴───────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use this table as an example to pull stats\n",
    "# collect standard price per qty from Received order\n",
    "\n",
    "dfReceipt.groupby(\"PRODUCT_ID\").agg(pl.sum(\"QTY\").alias(\"avg_qty_ordered\"), pl.sum(\"TOTAL\").alias(\"avg_price_paid\")).join(dfProduct, on=\"PRODUCT_ID\", how=\"inner\").sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: building prompt\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST DATA Prompts ##\n",
    "# respond in one word, is there an anomaly in this data.\n",
    "# find anomalies in this data. \n",
    "\n",
    "# Record 1\n",
    "# For a Product # XXX , on an average, there are XXX purchase Orders created.\n",
    "# on average, XXX % of Purchase orders are received on time, and\n",
    "# amount charge on invoice has average standard XXX.XXX % variance.\n",
    "# is it ok to pay such an invoice ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Checking one Invoice\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PO_ID</th><th>AS_OF_DATE</th><th>CUSTOMER_ID</th><th>VENDOR_ID</th><th>PRODUCT_ID</th><th>QTY</th><th>PRODUCT</th><th>PRODUCT_CATEGORY</th><th>MANUFACTURER</th><th>PRICE</th><th>TOTAL</th><th>PRODUCT_right</th><th>PRODUCT_CATEGORY_right</th><th>MANUFACTURER_right</th><th>PRICE_right</th><th>RECV_STATUS</th></tr><tr><td>i64</td><td>datetime[μs]</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>bool</td></tr></thead><tbody><tr><td>51383</td><td>2023-04-16 00:00:00</td><td>7743</td><td>1962</td><td>4686</td><td>15</td><td>&quot;Product Number…</td><td>&quot;1-07-919635-8&quot;</td><td>&quot;Rodriguez, San…</td><td>8970</td><td>134550</td><td>&quot;Product Number…</td><td>&quot;1-07-919635-8&quot;</td><td>&quot;Rodriguez, San…</td><td>8970</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 16)\n",
       "┌───────┬──────────┬───────────┬───────────┬───┬────────────┬────────────┬───────────┬─────────────┐\n",
       "│ PO_ID ┆ AS_OF_DA ┆ CUSTOMER_ ┆ VENDOR_ID ┆ … ┆ PRODUCT_CA ┆ MANUFACTUR ┆ PRICE_rig ┆ RECV_STATUS │\n",
       "│ ---   ┆ TE       ┆ ID        ┆ ---       ┆   ┆ TEGORY_rig ┆ ER_right   ┆ ht        ┆ ---         │\n",
       "│ i64   ┆ ---      ┆ ---       ┆ i64       ┆   ┆ ht         ┆ ---        ┆ ---       ┆ bool        │\n",
       "│       ┆ datetime ┆ i64       ┆           ┆   ┆ ---        ┆ str        ┆ i64       ┆             │\n",
       "│       ┆ [μs]     ┆           ┆           ┆   ┆ str        ┆            ┆           ┆             │\n",
       "╞═══════╪══════════╪═══════════╪═══════════╪═══╪════════════╪════════════╪═══════════╪═════════════╡\n",
       "│ 51383 ┆ 2023-04- ┆ 7743      ┆ 1962      ┆ … ┆ 1-07-91963 ┆ Rodriguez, ┆ 8970      ┆ true        │\n",
       "│       ┆ 16       ┆           ┆           ┆   ┆ 5-8        ┆ Sandoval   ┆           ┆             │\n",
       "│       ┆ 00:00:00 ┆           ┆           ┆   ┆            ┆ and Boyd   ┆           ┆             │\n",
       "└───────┴──────────┴───────────┴───────────┴───┴────────────┴────────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReceiptSampleCheck = dfReceipt.filter(pl.col(\"PO_ID\") == 51383)\n",
    "dfReceiptSampleCheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: run invoice prompt through LLM (large language model) \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dfReceiptSampleCheck = dfReceipt.filter(pl.col(\"PO_ID\") == 51383)\n",
    "# out.head()\n",
    "\n",
    "prompt = \"respond in one word, is there an anomaly in this data. \"\n",
    "prompt += \"For a Product # XXX , on an average, there are XXX purchase Orders created. \"\n",
    "prompt += \"on average, XXX % of Purchase orders are received on time, and \"\n",
    "prompt += \"is it ok to pay such an invoice ?\"\n",
    "prompt\n",
    "\n",
    "def callChatGPT(prompt):\n",
    "    # completion = openai.ChatCompletion.create(\n",
    "    # model=model_engine,\n",
    "    # messages=[\n",
    "    #     {\"role\": \"user\", \"content\": prompt}\n",
    "    # ])\n",
    "    # return completion.choices[0].message.content\n",
    "    return \"Yes\"\n",
    "\n",
    "def callLlama(prompt):\n",
    "    # results = generator.chat_completion(\n",
    "    #     dialogs,  # type: ignore\n",
    "    #     max_gen_len=max_gen_len,\n",
    "    #     temperature=temperature,\n",
    "    #     top_p=top_p,\n",
    "    # )\n",
    "    # return result['generation']['content']\n",
    "    return \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicate Invoices\n",
    "---\n",
    "\n",
    "- Step 1: Read Image content to text\n",
    "- Step 2: Create Corpus of documents\n",
    "- Step 3: Remove punctuations, Pronouns etc.\n",
    "- Step 4: Create bi | n-gram tokens\n",
    "- Step 5: Creating Individual Rows of a Document Term Matrix | Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach to locate Duplicate Invoice\n",
    "- Approach 1: Compare line by line\n",
    "- Approach 2: Compare TF-IDF \n",
    "- Approach 3: Compare Hash Trick Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Duplicate Invoices\n",
    "#########################\n",
    "\n",
    "# Step 1: Read Image content to text\n",
    "#######################################\n",
    "# Scripts read text from images\n",
    "#######################################\n",
    "# py -m pip install pytesseract : open source\n",
    "# py -m pip install PIL\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "##############################################################################\n",
    "# in case if tesseract is not included in PATH\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\amit.la\\WIP\\RPA\\downloads\\ts\\tesseract.exe'\n",
    "##############################################################################\n",
    "\n",
    "def read_image_text(image_path):\n",
    "    \"\"\"\n",
    "    Reads text from an image file using Tesseract OCR.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the input image.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted text from the image.\n",
    "    \"\"\"\n",
    "    # Load the image file\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Use Tesseract OCR to extract the text from the image\n",
    "    text = pytesseract.image_to_string(image)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "image_path = \"../downloads/AAPL.png\"\n",
    "# image_path = \"../downloads/medical_form.png\"\n",
    "# image_path = \"../downloads/email.png\"\n",
    "# image_path = \"../downloads/vaccine.png\"\n",
    "# image_path = \"../downloads/blurry_1.png\"\n",
    "# image_path = \"../downloads/blurry_2.png\"\n",
    "text = read_image_text(image_path)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create Corpus of documents\n",
    "# Step 3: Remove punctuations, Pronouns etc.\n",
    "# Step 4: Create bi | n-gram tokens\n",
    "# Step 5: Creating Individual Rows of a Document Term Matrix | Tensors\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# tokens = nltk.word_tokenize(text)\n",
    "# tokens\n",
    "\n",
    "# text.discard('\\n')\n",
    "# create bi-grams\n",
    "# list(bigrams(['more', 'is', 'said', 'than', 'done']))\n",
    "\n",
    "######################\n",
    "## tokenize by words\n",
    "######################\n",
    "from nltk.tokenize import word_tokenize\n",
    "print(word_tokenize(text))\n",
    "\n",
    "\n",
    "######################\n",
    "## tokenize by sentence\n",
    "######################\n",
    "from nltk.tokenize import sent_tokenize\n",
    "print(sent_tokenize(text))\n",
    "\n",
    "######################\n",
    "## generate bag of words\n",
    "######################\n",
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1: Compare line by line\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple code to compare txt files line by line\n",
    "# find similarities\n",
    "\n",
    "with open('input_1.txt', 'r') as file1:\n",
    "    with open('input_2.txt', 'r') as file2:\n",
    "        same = set(file1).intersection(file2)\n",
    "\n",
    "same.discard('\\n')\n",
    "\n",
    "with open('out.txt', 'w') as file_out:\n",
    "    for line in same:\n",
    "        file_out.write(line)\n",
    "\n",
    "# simple code to compare txt files line by line\n",
    "# find difference\n",
    "\n",
    "with open('input_1.txt', 'r') as file1:\n",
    "    with open('input_2.txt', 'r') as file2:\n",
    "        difference = set(file1).difference(file2)\n",
    "\n",
    "difference.discard('\\n')\n",
    "\n",
    "with open('out.txt', 'w') as file_out:\n",
    "    for line in difference:\n",
    "        file_out.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2: Compare TF-IDF\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "fdist1 = FreqDist(text)\n",
    "print(fdist1)\n",
    "fdist1.most_common(50)\n",
    "\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "for doc in tfidf[corpus]:\n",
    "    print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity index\n",
    "# building the index\n",
    "sims = gensim.similarities.Similarity('workdir/',tf_idf[corpus],\n",
    "                                        num_features=len(dictionary))\n",
    "\n",
    "file2_docs = []\n",
    "\n",
    "with open ('demofile2.txt') as f:\n",
    "    tokens = sent_tokenize(f.read())\n",
    "    for line in tokens:\n",
    "        file2_docs.append(line)\n",
    "\n",
    "print(\"Number of documents:\",len(file2_docs))  \n",
    "for line in file2_docs:\n",
    "    query_doc = [w.lower() for w in word_tokenize(line)]\n",
    "    query_doc_bow = dictionary.doc2bow(query_doc) #update an existing dictionary and\n",
    "# create bag of words\n",
    "\n",
    "\n",
    "# perform a similarity query against the corpus\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "# print(document_number, document_similarity)\n",
    "print('Comparing Result:', sims[query_doc_tf_idf]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # building the index\n",
    "sims = gensim.similarities.Similarity('downloads/',tf_idf[corpus],\n",
    "                                        num_features=len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 3: Compare Hash Trick Documents\n",
    "---\n",
    "\n",
    "`CUDA | Tensor comparison on GPU machines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert words into Tensor\n",
    "\n",
    "# Trick #1\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "labels = ['cat', 'dog', 'mouse', 'elephant', 'pandas']\n",
    "le = preprocessing.LabelEncoder()\n",
    "targets = le.fit_transform(labels)\n",
    "# targets: array([0, 1, 2, 3, 4])\n",
    "\n",
    "targets = torch.as_tensor(targets)\n",
    "# targets: tensor([0, 1, 2, 3, 4])\n",
    "\n",
    "#Trick 2\n",
    "In[]\n",
    "import torch\n",
    "\n",
    "words = ['שלום', 'beautiful', 'world']\n",
    "max_l = 0\n",
    "ts_list = []\n",
    "for w in words:\n",
    "    ts_list.append(torch.ByteTensor(list(bytes(w, 'utf8'))))\n",
    "    max_l = max(ts_list[-1].size()[0], max_l)\n",
    "\n",
    "w_t = torch.zeros((len(ts_list), max_l), dtype=torch.uint8)\n",
    "for i, ts in enumerate(ts_list):\n",
    "    w_t[i, 0:ts.size()[0]] = ts\n",
    "w_t\n",
    "\n",
    "Out[]\n",
    "tensor([[215, 169, 215, 156, 215, 149, 215, 157,   0],\n",
    "        [ 98, 101,  97, 117, 116, 105, 102, 117, 108],\n",
    "        [119, 111, 114, 108, 100,   0,   0,   0,   0]], dtype=torch.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The use case discussed above exemplify sophisticated business processes and there is certainly lot more which is not covered. \n",
    "\n",
    "This use case merely scratch the surface of what can be achieved with these advanced tools. \n",
    "\n",
    "You may argue that the same results can be attained using simple algebraic mathematics with these datasets, and I fully support and agree with this observation.\n",
    "\n",
    "In essence, the entire field, encompassing Data Science, Python, Llama, and ChatGPT, revolves around uncovering statistical associations within data.\n",
    "\n",
    "However, it is crucial to recognize that the deployment of Llama or ChatGPT-like models does not surpass the importance of traditional statistics,\n",
    "instead, they should be employed to streamline specific tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
