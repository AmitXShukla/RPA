{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90fa9eca-e5ce-4f02-afa6-d11f45b62f5a",
   "metadata": {},
   "source": [
    "## Scrape text and download csv pdf image files from webpage\n",
    "---\n",
    "\n",
    "`The intended functionality of this code is not achieved.`\n",
    "\n",
    "I would like to clarify that this video is not intended to be a sensational blog that teaches you how to hack government websites and turn you into a hacker overnight. \n",
    "\n",
    "If that's what you're expecting, you will be disappointed. \n",
    "\n",
    "Instead, I will be discussing the pitfalls of using such code for hacking purposes.\n",
    "\n",
    "I would also like to discourage you from attempting to hack websites using such code, as it could result in legal consequences. \n",
    "\n",
    "However, if you're interested in ethical hacking, that is a topic for another day.\n",
    "\n",
    "Although, I make living of writing hackers code, Please note that I won't be creating videos on this topic.\n",
    "\n",
    "---\n",
    "This tutorial will demonstrate how to read text from a web page using Python beautifulsoup4 module.\n",
    "\n",
    "Frequently, we need to read and store dynamic content from web pages.\n",
    "\n",
    "The tutorial will cover the following:\n",
    "\n",
    "- Downloading content from web pages\n",
    "- read web text and write functions to retrieve urls, emails and phone numbers\n",
    "\n",
    "`Disclaimer: This code doesn't always work expected with websites where JavaScript is disabled or in cases, where it's prohibited to download copyright content with out consent. Most of modern data website required users to sign and obtain appropriate API Keys to download content.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44ba9c-0eb8-4a7e-b160-924c3ff6cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# create RPA Virtual environment\n",
    "################################\n",
    "# py -m venv RPA\n",
    "# RPA\\Scripts\\activate.bat\n",
    "# import sys\n",
    "# sys.path\n",
    "# py -m pip --version\n",
    "\n",
    "############################################\n",
    "## MAKE SURE these packages are installed ##\n",
    "############################################\n",
    "# py -m pip install beautifulsoup4\n",
    "################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e33de39f",
   "metadata": {},
   "source": [
    "## ChatGPT generated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4697a-e843-4746-8190-dd97737981ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Define the URL of the webpage to scrape\n",
    "# url = \"https://www.github.com/AmitXShukla/RPA\"\n",
    "# url = \"https://twitter.com/ashuklax\" # twitter doesn't enable JavaScript at browser\n",
    "# url = \"https://en.wikipedia.org/wiki/OpenAI\"\n",
    "url = \"https://www.ucla.edu/contact\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the links on the page\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "# Define a function to download a file given its URL and file name\n",
    "def download_file(url, file_name):\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        response = requests.get(url)\n",
    "        f.write(response.content)\n",
    "\n",
    "# Loop through the links and download any CSV, PDF, or image files\n",
    "for link in links:\n",
    "    href = link.get(\"href\")\n",
    "    if href:\n",
    "        # Check if the link is for a CSV, PDF, or image file\n",
    "        if href.endswith(\".csv\") or href.endswith(\".pdf\") or href.endswith(\".jpg\") or href.endswith(\".png\"):\n",
    "            # If the link is a relative path, construct the full URL\n",
    "            if href.startswith(\"/\"):\n",
    "                href = url + href[1:]\n",
    "            # Download the file using the link's URL and file name\n",
    "            file_name = os.path.basename(href)\n",
    "            download_file(href, file_name)\n",
    "\n",
    "# Extract text from the webpage\n",
    "text = soup.get_text()\n",
    "\n",
    "# Print the extracted text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a247c559-0d63-44aa-a9d2-abf12cfe2250",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once you have the library installed, you can use this code to scrape a webpage, download any CSV, PDF, or image files on the page, and extract text from the page. Note that you should always check the terms of service and robots.txt file of a website before scraping it, as some websites may prohibit scraping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
