{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fa9eca-e5ce-4f02-afa6-d11f45b62f5a",
   "metadata": {},
   "source": [
    "# ask ChatGPT to write code for Scrape text and download csv pdf image files from webpage\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "710d1f86-fb58-41d5-afc9-5890ffe67808",
   "metadata": {},
   "source": [
    "################################\n",
    "# create RPA Virtual environment\n",
    "################################\n",
    "# py -m venv RPA\n",
    "# RPA\\Scripts\\activate.bat\n",
    "# import sys\n",
    "# sys.path\n",
    "# py -m pip --version\n",
    "\n",
    "############################################\n",
    "## MAKE SURE these packages are installed ##\n",
    "############################################\n",
    "# py -m pip install beautifulsoup4\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4697a-e843-4746-8190-dd97737981ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Define the URL of the webpage to scrape\n",
    "url = \"https://www.example.com/\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content of the page using Beautiful Soup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the links on the page\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "# Define a function to download a file given its URL and file name\n",
    "def download_file(url, file_name):\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        response = requests.get(url)\n",
    "        f.write(response.content)\n",
    "\n",
    "# Loop through the links and download any CSV, PDF, or image files\n",
    "for link in links:\n",
    "    href = link.get(\"href\")\n",
    "    if href:\n",
    "        # Check if the link is for a CSV, PDF, or image file\n",
    "        if href.endswith(\".csv\") or href.endswith(\".pdf\") or href.endswith(\".jpg\") or href.endswith(\".png\"):\n",
    "            # If the link is a relative path, construct the full URL\n",
    "            if href.startswith(\"/\"):\n",
    "                href = url + href[1:]\n",
    "            # Download the file using the link's URL and file name\n",
    "            file_name = os.path.basename(href)\n",
    "            download_file(href, file_name)\n",
    "\n",
    "# Extract text from the webpage\n",
    "text = soup.get_text()\n",
    "\n",
    "# Print the extracted text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a247c559-0d63-44aa-a9d2-abf12cfe2250",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once you have the library installed, you can use this code to scrape a webpage, download any CSV, PDF, or image files on the page, and extract text from the page. Note that you should always check the terms of service and robots.txt file of a website before scraping it, as some websites may prohibit scraping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
